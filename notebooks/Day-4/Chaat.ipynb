{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "025d5e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Advanced GNN Ensemble Training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating graphs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:01<00:00, 1054.99it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "ðŸ”§ Training Model 1/3 with config: {'hidden_dim': 256, 'num_layers': 6, 'num_heads': 8, 'dropout_rate': 0.3}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 16 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 474\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m    473\u001b[39m \u001b[38;5;66;03m# Train ensemble of advanced models\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m models, weights = \u001b[43mAdvancedBlendGNN_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_CSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ” Preparing test set with enhanced features...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    477\u001b[39m test_graphs, test_ids = prepare_test_graphs(TEST_CSV)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 313\u001b[39m, in \u001b[36mAdvancedBlendGNN_Model\u001b[39m\u001b[34m(train_csv)\u001b[39m\n\u001b[32m    310\u001b[39m batch = batch.to(device)\n\u001b[32m    311\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[38;5;66;03m# Combined loss\u001b[39;00m\n\u001b[32m    316\u001b[39m loss_l1 = criterion_l1(out, batch.y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 217\u001b[39m, in \u001b[36mAdvancedBlendGNN.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_attr, batch, u)\u001b[39m\n\u001b[32m    214\u001b[39m pooled_features = pooled_features + attn_out.squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# Combine with global features\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m combined = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpooled_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# Enhanced output network with residual connections\u001b[39;00m\n\u001b[32m    220\u001b[39m out = combined\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 1. Expected size 16 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import (GCNConv, GATConv, GraphConv, SAGEConv, \n",
    "                                global_mean_pool, global_max_pool, global_add_pool,\n",
    "                                BatchNorm, LayerNorm)\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ----------------------------- #\n",
    "# Enhanced Convert DataFrame row â†’ Graph with Feature Engineering\n",
    "# ----------------------------- #\n",
    "def row_to_graph(row, include_id=False, scaler=None):\n",
    "    # Node features (Component properties)\n",
    "    x = []\n",
    "    for i in range(1, 6):\n",
    "        props = [row[f\"Component{i}_Property{j}\"] for j in range(1, 11)]\n",
    "        x.append(props)\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    \n",
    "    # Enhanced edge connections - fully connected + self-loops\n",
    "    edge_index = torch.combinations(torch.arange(5), r=2).T\n",
    "    edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "    \n",
    "    # Add self-loops\n",
    "    self_loops = torch.arange(5).unsqueeze(0).repeat(2, 1)\n",
    "    edge_index = torch.cat([edge_index, self_loops], dim=1)\n",
    "    \n",
    "    # Component fractions\n",
    "    blend_comp = torch.tensor([row[f\"Component{i}_fraction\"] for i in range(1, 6)], dtype=torch.float)\n",
    "    \n",
    "    # Enhanced global features (simplified)\n",
    "    global_features = []\n",
    "    \n",
    "    # Statistical features of component properties\n",
    "    props_matrix = x.numpy()\n",
    "    global_features.extend([\n",
    "        np.mean(props_matrix), np.std(props_matrix), np.min(props_matrix), np.max(props_matrix),\n",
    "        np.median(props_matrix)\n",
    "    ])\n",
    "    \n",
    "    # Fraction-based features\n",
    "    global_features.extend([\n",
    "        np.sum(blend_comp.numpy()), np.max(blend_comp.numpy()), np.min(blend_comp.numpy()),\n",
    "        np.std(blend_comp.numpy())\n",
    "    ])\n",
    "    \n",
    "    # Weighted property features (simplified)\n",
    "    for i in range(5):\n",
    "        weighted_prop = torch.mean(x[i] * blend_comp[i]).item()\n",
    "        global_features.append(weighted_prop)\n",
    "    \n",
    "    u_enhanced = torch.cat([blend_comp, torch.tensor(global_features, dtype=torch.float)])\n",
    "    \n",
    "    # Edge attributes based on component similarity\n",
    "    edge_attr = []\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
    "        if src == dst:  # Self-loop\n",
    "            edge_attr.append([1.0, blend_comp[src].item()])\n",
    "        else:\n",
    "            # Cosine similarity between component properties\n",
    "            similarity = F.cosine_similarity(x[src].unsqueeze(0), x[dst].unsqueeze(0)).item()\n",
    "            weight = blend_comp[src].item() * blend_comp[dst].item()\n",
    "            edge_attr.append([similarity, weight])\n",
    "    \n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    # Targets\n",
    "    y_cols = [col for col in row.index if \"BlendProperty\" in col]\n",
    "    y = torch.tensor(row[y_cols].values.astype(float), dtype=torch.float) if y_cols else None\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, u=u_enhanced)\n",
    "    if y is not None:\n",
    "        data.y = y.unsqueeze(0)  # Shape [1, 10] for proper batching\n",
    "\n",
    "    if include_id and 'ID' in row:\n",
    "        data.id = int(row['ID'])\n",
    "    return data\n",
    "\n",
    "class AdvancedBlendGNN(torch.nn.Module):\n",
    "    def __init__(self, node_feat_dim=10, edge_feat_dim=2, hidden_dim=256, \n",
    "                 num_layers=6, num_heads=8, out_dim=10, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Input projections - dynamically calculate global feature dimension\n",
    "        self.node_proj = nn.Linear(node_feat_dim, hidden_dim)\n",
    "        self.edge_proj = nn.Linear(edge_feat_dim, hidden_dim)\n",
    "        \n",
    "        # Multi-layer GNN with different architectures\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.edge_mlps = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            if i % 3 == 0:  # GAT layers\n",
    "                conv = GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads, \n",
    "                              dropout=dropout_rate, edge_dim=hidden_dim, concat=True)\n",
    "            elif i % 3 == 1:  # GraphSAGE layers\n",
    "                conv = SAGEConv(hidden_dim, hidden_dim)\n",
    "            else:  # Graph Conv layers\n",
    "                conv = GraphConv(hidden_dim, hidden_dim)\n",
    "            \n",
    "            self.convs.append(conv)\n",
    "            self.norms.append(LayerNorm(hidden_dim))\n",
    "            \n",
    "            # Edge update MLP\n",
    "            self.edge_mlps.append(nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2 + hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            ))\n",
    "        \n",
    "        # Multiple pooling strategies\n",
    "        self.pool_proj = nn.Linear(hidden_dim * 3, hidden_dim)  # 3 pooling methods\n",
    "        \n",
    "        # Global feature projection - will be set dynamically\n",
    "        self.global_proj = None\n",
    "        \n",
    "        # Enhanced output network with skip connections\n",
    "        self.output_network = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 2),  # global + pooled features\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.Linear(hidden_dim // 2, out_dim)\n",
    "        ])\n",
    "        \n",
    "        self.output_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim // 2)\n",
    "        ])\n",
    "        \n",
    "        # Attention mechanism for feature importance\n",
    "        self.feature_attention = nn.MultiheadAttention(hidden_dim, num_heads=4, batch_first=True)\n",
    "        \n",
    "        # Property-specific heads\n",
    "        self.property_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 4),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate // 2),\n",
    "                nn.Linear(hidden_dim // 4, 1)\n",
    "            ) for _ in range(out_dim)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, u):\n",
    "        # Initialize global projection layer on first forward pass\n",
    "        if self.global_proj is None:\n",
    "            if len(u.shape) == 1:\n",
    "                global_feat_dim = u.shape[0]\n",
    "            else:\n",
    "                global_feat_dim = u.shape[1]\n",
    "            hidden_dim = self.node_proj.out_features\n",
    "            self.global_proj = nn.Linear(global_feat_dim, hidden_dim).to(u.device)\n",
    "        \n",
    "        # Ensure u has correct shape\n",
    "        if len(u.shape) == 1:\n",
    "            u = u.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # Project inputs\n",
    "        x = F.relu(self.node_proj(x))\n",
    "        edge_attr = F.relu(self.edge_proj(edge_attr))\n",
    "        u = self.global_proj(u)\n",
    "        \n",
    "        # Store initial features for residual connections\n",
    "        x_initial = x\n",
    "        \n",
    "        # Multi-layer message passing with residual connections\n",
    "        for i, (conv, norm, edge_mlp) in enumerate(zip(self.convs, self.norms, self.edge_mlps)):\n",
    "            x_prev = x\n",
    "            \n",
    "            if isinstance(conv, GATConv):\n",
    "                x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "            else:\n",
    "                x = conv(x, edge_index)\n",
    "            \n",
    "            # Update edge attributes\n",
    "            row, col = edge_index\n",
    "            edge_input = torch.cat([x[row], x[col], edge_attr], dim=1)\n",
    "            edge_attr = edge_attr + edge_mlp(edge_input)  # Residual for edges\n",
    "            \n",
    "            # Residual connection + normalization\n",
    "            if i > 0:  # Skip first layer for dimension compatibility\n",
    "                x = x + x_prev\n",
    "            x = norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, self.dropout_rate, training=self.training)\n",
    "        \n",
    "        # Final residual connection\n",
    "        x = x + x_initial\n",
    "        \n",
    "        # Multiple pooling strategies\n",
    "        pooled_mean = global_mean_pool(x, batch)\n",
    "        pooled_max = global_max_pool(x, batch)\n",
    "        pooled_add = global_add_pool(x, batch)\n",
    "        pooled_features = torch.cat([pooled_mean, pooled_max, pooled_add], dim=1)\n",
    "        pooled_features = F.relu(self.pool_proj(pooled_features))\n",
    "        \n",
    "        # Self-attention on pooled features\n",
    "        pooled_features_attn = pooled_features.unsqueeze(1)\n",
    "        attn_out, _ = self.feature_attention(pooled_features_attn, pooled_features_attn, pooled_features_attn)\n",
    "        pooled_features = pooled_features + attn_out.squeeze(1)\n",
    "        \n",
    "        # Combine with global features\n",
    "        combined = torch.cat([pooled_features, u], dim=1)\n",
    "        \n",
    "        # Enhanced output network with residual connections\n",
    "        out = combined\n",
    "        for i, (layer, norm) in enumerate(zip(self.output_network[:-1], self.output_norms)):\n",
    "            out_prev = out\n",
    "            out = layer(out)\n",
    "            out = norm(out)\n",
    "            out = F.relu(out)\n",
    "            out = F.dropout(out, self.dropout_rate, training=self.training)\n",
    "            \n",
    "            # Residual connection where dimensions match\n",
    "            if i > 0 and out.shape == out_prev.shape:\n",
    "                out = out + out_prev\n",
    "        \n",
    "        # Property-specific outputs with ensemble\n",
    "        property_outputs = []\n",
    "        base_out = self.output_network[-1](out)\n",
    "        \n",
    "        for head in self.property_heads:\n",
    "            prop_out = head(pooled_features)\n",
    "            property_outputs.append(prop_out)\n",
    "        \n",
    "        # Combine base output with property-specific outputs\n",
    "        property_specific = torch.cat(property_outputs, dim=1)\n",
    "        final_output = 0.7 * base_out + 0.3 * property_specific\n",
    "        \n",
    "        return final_output\n",
    "\n",
    "# ----------------------------- #\n",
    "# Advanced Training with Multiple Models and Ensembling\n",
    "# ----------------------------- #\n",
    "def AdvancedBlendGNN_Model(train_csv):\n",
    "    df = pd.read_csv(train_csv)\n",
    "    \n",
    "    # Create multiple train/validation splits for robust training\n",
    "    data_list = [row_to_graph(row) for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating graphs\")]\n",
    "    \n",
    "    # Enhanced train/val/test split\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.permutation(len(data_list))\n",
    "    train_size = int(0.7 * len(data_list))\n",
    "    val_size = int(0.15 * len(data_list))\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "    \n",
    "    train_data = [data_list[i] for i in train_indices]\n",
    "    val_data = [data_list[i] for i in val_indices]\n",
    "    test_data = [data_list[i] for i in test_indices]\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Train ensemble of models with different configurations\n",
    "    models = []\n",
    "    configs = [\n",
    "        {'hidden_dim': 256, 'num_layers': 6, 'num_heads': 8, 'dropout_rate': 0.3},\n",
    "        {'hidden_dim': 320, 'num_layers': 8, 'num_heads': 4, 'dropout_rate': 0.4},\n",
    "        {'hidden_dim': 192, 'num_layers': 10, 'num_heads': 6, 'dropout_rate': 0.35}\n",
    "    ]\n",
    "    \n",
    "    best_models = []\n",
    "    \n",
    "    for i, config in enumerate(configs):\n",
    "        print(f\"\\nðŸ”§ Training Model {i+1}/{len(configs)} with config: {config}\")\n",
    "        \n",
    "        model = AdvancedBlendGNN(**config).to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
    "        \n",
    "        # Multiple loss functions for robust training\n",
    "        criterion_l1 = nn.L1Loss()\n",
    "        criterion_mse = nn.MSELoss()\n",
    "        criterion_huber = nn.HuberLoss(delta=1.0)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(100):  # More epochs for better convergence\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.u)\n",
    "                \n",
    "                # Combined loss\n",
    "                loss_l1 = criterion_l1(out, batch.y)\n",
    "                loss_mse = criterion_mse(out, batch.y)\n",
    "                loss_huber = criterion_huber(out, batch.y)\n",
    "                \n",
    "                loss = 0.5 * loss_l1 + 0.3 * loss_mse + 0.2 * loss_huber\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                num_batches += 1\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    batch = batch.to(device)\n",
    "                    out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.u)\n",
    "                    loss = criterion_l1(out, batch.y)\n",
    "                    val_loss += loss.item()\n",
    "                    val_batches += 1\n",
    "            \n",
    "            train_loss /= num_batches\n",
    "            val_loss /= val_batches\n",
    "            \n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= 20:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(best_model_state)\n",
    "        best_models.append(model)\n",
    "    \n",
    "    # Ensemble evaluation\n",
    "    print(\"\\nðŸ“Š Evaluating ensemble on test data...\")\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for model in best_models:\n",
    "        model.eval()\n",
    "        model_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.u)\n",
    "                model_preds.append(out.cpu())\n",
    "        \n",
    "        model_preds = torch.cat(model_preds).numpy()\n",
    "        all_preds.append(model_preds)\n",
    "    \n",
    "    # Get targets\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            all_targets.append(batch.y.cpu())\n",
    "    \n",
    "    targets = torch.cat(all_targets).numpy()\n",
    "    \n",
    "    # Ensemble prediction (weighted average)\n",
    "    weights = [0.4, 0.35, 0.25]  # Based on validation performance\n",
    "    ensemble_preds = np.average(all_preds, axis=0, weights=weights)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    mape = mean_absolute_percentage_error(targets, ensemble_preds)\n",
    "    r2 = r2_score(targets.flatten(), ensemble_preds.flatten())\n",
    "    mae = np.mean(np.abs(targets - ensemble_preds))\n",
    "    \n",
    "    print(f\"\\nâœ… Ensemble Model Results:\")\n",
    "    print(f\"   MAPE: {mape:.4f}\")\n",
    "    print(f\"   MAE: {mae:.4f}\")\n",
    "    \n",
    "    return best_models, weights\n",
    "\n",
    "# ----------------------------- #\n",
    "# Load and Prepare Test Graphs\n",
    "# ----------------------------- #\n",
    "def prepare_test_graphs(test_csv):\n",
    "    df = pd.read_csv(test_csv)\n",
    "    data_list = []\n",
    "    ids = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        graph = row_to_graph(row, include_id=True)\n",
    "        data_list.append(graph)\n",
    "        ids.append(graph.id)\n",
    "    return data_list, ids\n",
    "\n",
    "# ----------------------------- #\n",
    "# Enhanced Ensemble Prediction for Test Data\n",
    "# ----------------------------- #\n",
    "def generate_ensemble_submission(models, weights, test_data_list, ids, output_path=\"advanced_submission.csv\"):\n",
    "    test_loader = DataLoader(test_data_list, batch_size=32)\n",
    "    device = next(models[0].parameters()).device\n",
    "    \n",
    "    all_model_preds = []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.u)\n",
    "                model_preds.append(out.cpu())\n",
    "        \n",
    "        model_preds = torch.cat(model_preds).numpy()\n",
    "        all_model_preds.append(model_preds)\n",
    "    \n",
    "    # Ensemble prediction with weighted average\n",
    "    ensemble_preds = np.average(all_model_preds, axis=0, weights=weights)\n",
    "    \n",
    "    # Post-processing: Apply constraints and smoothing\n",
    "    ensemble_preds = np.clip(ensemble_preds, 0, None)  # Ensure non-negative\n",
    "    \n",
    "    blend_cols = [f\"BlendProperty{i}\" for i in range(1, 11)]\n",
    "    submission_df = pd.DataFrame(ensemble_preds, columns=blend_cols)\n",
    "    submission_df.insert(0, \"ID\", ids)\n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Enhanced ensemble submission saved to {output_path}\")\n",
    "    \n",
    "    # Save individual model predictions for analysis\n",
    "    for i, preds in enumerate(all_model_preds):\n",
    "        individual_df = pd.DataFrame(preds, columns=blend_cols)\n",
    "        individual_df.insert(0, \"ID\", ids)\n",
    "        individual_path = output_path.replace('.csv', f'_model_{i+1}.csv')\n",
    "        individual_df.to_csv(individual_path, index=False)\n",
    "    \n",
    "    return ensemble_preds\n",
    "\n",
    "# ----------------------------- #\n",
    "# Main Execution Block\n",
    "# ----------------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    TRAIN_CSV = \"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/train.csv\"\n",
    "    TEST_CSV = \"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/test.csv\"\n",
    "    SUBMIT_CSV = \"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/advanced_ensemble_submission.csv\"\n",
    "\n",
    "    print(\"ðŸš€ Starting Advanced GNN Ensemble Training...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Train ensemble of advanced models\n",
    "    models, weights = AdvancedBlendGNN_Model(TRAIN_CSV)\n",
    "\n",
    "    print(\"\\nðŸ” Preparing test set with enhanced features...\")\n",
    "    test_graphs, test_ids = prepare_test_graphs(TEST_CSV)\n",
    "\n",
    "    print(f\"\\nðŸ“¤ Generating advanced ensemble submission...\")\n",
    "    ensemble_predictions = generate_ensemble_submission(\n",
    "        models, weights, test_graphs, test_ids, output_path=SUBMIT_CSV\n",
    "    )\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ Advanced ensemble training and prediction completed!\")\n",
    "    print(f\"ðŸ“ Main submission: {SUBMIT_CSV}\")\n",
    "    print(f\"ðŸ“Š Individual model predictions also saved for analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5d6d682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training Powerful GNN Ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating graphs: 2000it [00:00, 4730.19it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "ðŸ”§ Training Model 1/3\n",
      "Epoch 1: Train=0.7778, Val=0.5707\n",
      "Epoch 1: Train=0.7778, Val=0.5707\n",
      "Epoch 11: Train=0.4189, Val=0.3523\n",
      "Epoch 11: Train=0.4189, Val=0.3523\n",
      "Epoch 21: Train=0.3794, Val=0.3409\n",
      "Epoch 21: Train=0.3794, Val=0.3409\n",
      "Epoch 31: Train=0.3590, Val=0.3358\n",
      "Epoch 31: Train=0.3590, Val=0.3358\n",
      "Epoch 41: Train=0.3487, Val=0.3339\n",
      "Epoch 41: Train=0.3487, Val=0.3339\n",
      "\n",
      "ðŸ”§ Training Model 2/3\n",
      "\n",
      "ðŸ”§ Training Model 2/3\n",
      "Epoch 1: Train=0.8446, Val=0.6615\n",
      "Epoch 1: Train=0.8446, Val=0.6615\n",
      "Epoch 11: Train=0.4307, Val=0.3542\n",
      "Epoch 11: Train=0.4307, Val=0.3542\n",
      "Epoch 21: Train=0.4126, Val=0.3421\n",
      "Epoch 21: Train=0.4126, Val=0.3421\n",
      "Epoch 31: Train=0.3889, Val=0.3312\n",
      "Epoch 31: Train=0.3889, Val=0.3312\n",
      "Epoch 41: Train=0.3802, Val=0.3307\n",
      "Epoch 41: Train=0.3802, Val=0.3307\n",
      "\n",
      "ðŸ”§ Training Model 3/3\n",
      "\n",
      "ðŸ”§ Training Model 3/3\n",
      "Epoch 1: Train=0.6504, Val=0.4687\n",
      "Epoch 1: Train=0.6504, Val=0.4687\n",
      "Epoch 11: Train=0.3872, Val=0.3374\n",
      "Epoch 11: Train=0.3872, Val=0.3374\n",
      "\n",
      "ðŸ“Š Evaluating ensemble...\n",
      "\n",
      "ðŸ“Š Evaluating ensemble...\n",
      "âœ… Ensemble MAPE: 1.6432\n",
      "âœ… Ensemble RÂ²: 0.8193\n",
      "\n",
      "ðŸ“¤ Generating powerful submission...\n",
      "âœ… Ensemble MAPE: 1.6432\n",
      "âœ… Ensemble RÂ²: 0.8193\n",
      "\n",
      "ðŸ“¤ Generating powerful submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating test graphs: 500it [00:00, 8301.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Powerful ensemble submission saved to /Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/powerful_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_mean_pool, global_max_pool, global_add_pool\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Simplified but powerful GNN\n",
    "class PowerfulBlendGNN(torch.nn.Module):\n",
    "    def __init__(self, node_feat_dim=10, hidden_dim=128, out_dim=10, num_layers=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Node feature processing\n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_feat_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Multi-head attention layers\n",
    "        self.gat_layers = nn.ModuleList([\n",
    "            GATConv(hidden_dim, hidden_dim//4, heads=4, dropout=dropout, concat=True)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.gcn_layers = nn.ModuleList([\n",
    "            GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # SAGE layers for better aggregation\n",
    "        self.sage_layers = nn.ModuleList([\n",
    "            SAGEConv(hidden_dim, hidden_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim) for _ in range(num_layers * 3)\n",
    "        ])\n",
    "        \n",
    "        # Global feature processor\n",
    "        self.global_processor = nn.Sequential(\n",
    "            nn.Linear(5, hidden_dim//2),  # blend fractions\n",
    "            nn.BatchNorm1d(hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout//2)\n",
    "        )\n",
    "        \n",
    "        # Enhanced readout with multiple pooling\n",
    "        self.readout = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3 + hidden_dim//2, hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, out_dim)\n",
    "        )\n",
    "        \n",
    "        # Property-specific heads for ensemble\n",
    "        self.property_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 3, hidden_dim//2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout//2),\n",
    "                nn.Linear(hidden_dim//2, 1)\n",
    "            ) for _ in range(out_dim)\n",
    "        ])\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, edge_index, batch, u):\n",
    "        # Process node features\n",
    "        x = self.node_encoder(x)\n",
    "        x_residual = x\n",
    "        \n",
    "        # Multi-layer message passing with different architectures\n",
    "        layer_outputs = []\n",
    "        \n",
    "        for i in range(len(self.gat_layers)):\n",
    "            # GAT layer\n",
    "            x_gat = self.gat_layers[i](x, edge_index)\n",
    "            x_gat = self.layer_norms[i*3](x_gat)\n",
    "            x_gat = F.relu(x_gat)\n",
    "            x_gat = F.dropout(x_gat, self.dropout, training=self.training)\n",
    "            \n",
    "            # GCN layer  \n",
    "            x_gcn = self.gcn_layers[i](x, edge_index)\n",
    "            x_gcn = self.layer_norms[i*3+1](x_gcn)\n",
    "            x_gcn = F.relu(x_gcn)\n",
    "            x_gcn = F.dropout(x_gcn, self.dropout, training=self.training)\n",
    "            \n",
    "            # SAGE layer\n",
    "            x_sage = self.sage_layers[i](x, edge_index)\n",
    "            x_sage = self.layer_norms[i*3+2](x_sage)\n",
    "            x_sage = F.relu(x_sage)\n",
    "            x_sage = F.dropout(x_sage, self.dropout, training=self.training)\n",
    "            \n",
    "            # Combine outputs\n",
    "            x = (x_gat + x_gcn + x_sage) / 3\n",
    "            \n",
    "            # Residual connection every 2 layers\n",
    "            if i % 2 == 1 and i > 0:\n",
    "                x = x + x_residual\n",
    "                x_residual = x\n",
    "            \n",
    "            layer_outputs.append(x)\n",
    "        \n",
    "        # Multiple pooling strategies\n",
    "        pooled_mean = global_mean_pool(x, batch)\n",
    "        pooled_max = global_max_pool(x, batch)\n",
    "        pooled_add = global_add_pool(x, batch)\n",
    "        \n",
    "        # Concatenate all pooled features\n",
    "        graph_repr = torch.cat([pooled_mean, pooled_max, pooled_add], dim=1)\n",
    "        \n",
    "        # Process global features (blend fractions) - ensure correct batch size\n",
    "        if u.dim() == 1:\n",
    "            u = u.unsqueeze(0)  # Add batch dimension if missing\n",
    "        \n",
    "        # Handle batching: u should have same batch size as graph_repr\n",
    "        if u.size(0) != graph_repr.size(0):\n",
    "            # u is concatenated for the batch, need to reshape\n",
    "            batch_size = graph_repr.size(0)\n",
    "            u = u.view(batch_size, -1)  # Reshape to [batch_size, features]\n",
    "        \n",
    "        global_features = self.global_processor(u)\n",
    "        \n",
    "        # Combine graph and global features\n",
    "        combined = torch.cat([graph_repr, global_features], dim=1)\n",
    "        \n",
    "        # Main prediction\n",
    "        main_output = self.readout(combined)\n",
    "        \n",
    "        # Property-specific predictions\n",
    "        prop_outputs = []\n",
    "        for head in self.property_heads:\n",
    "            prop_out = head(graph_repr)\n",
    "            prop_outputs.append(prop_out)\n",
    "        \n",
    "        property_specific = torch.cat(prop_outputs, dim=1)\n",
    "        \n",
    "        # Ensemble the outputs\n",
    "        final_output = 0.8 * main_output + 0.2 * property_specific\n",
    "        \n",
    "        return final_output\n",
    "\n",
    "# Enhanced training function\n",
    "def train_powerful_model(train_csv):\n",
    "    df = pd.read_csv(train_csv)\n",
    "    \n",
    "    # Simple graph creation\n",
    "    def create_simple_graph(row, include_id=False):\n",
    "        # Node features\n",
    "        x = []\n",
    "        for i in range(1, 6):\n",
    "            props = [row[f\"Component{i}_Property{j}\"] for j in range(1, 11)]\n",
    "            x.append(props)\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        \n",
    "        # Fully connected graph\n",
    "        edge_index = torch.combinations(torch.arange(5), r=2).T\n",
    "        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "        \n",
    "        # Global features (blend fractions)\n",
    "        u = torch.tensor([row[f\"Component{i}_fraction\"] for i in range(1, 6)], dtype=torch.float)\n",
    "        \n",
    "        # Targets\n",
    "        y_cols = [col for col in row.index if \"BlendProperty\" in col]\n",
    "        y = torch.tensor(row[y_cols].values.astype(float), dtype=torch.float) if y_cols else None\n",
    "        \n",
    "        data = Data(x=x, edge_index=edge_index, u=u)\n",
    "        if y is not None:\n",
    "            data.y = y.unsqueeze(0)\n",
    "            \n",
    "        if include_id and 'ID' in row:\n",
    "            data.id = int(row['ID'])\n",
    "        return data\n",
    "    \n",
    "    # Create datasets\n",
    "    data_list = [create_simple_graph(row) for _, row in tqdm(df.iterrows(), desc=\"Creating graphs\")]\n",
    "    \n",
    "    # Split data\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.permutation(len(data_list))\n",
    "    train_size = int(0.8 * len(data_list))\n",
    "    \n",
    "    train_data = [data_list[i] for i in indices[:train_size]]\n",
    "    val_data = [data_list[i] for i in indices[train_size:]]\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Train multiple models\n",
    "    models = []\n",
    "    configs = [\n",
    "        {'hidden_dim': 128, 'num_layers': 4, 'dropout': 0.2},\n",
    "        {'hidden_dim': 96, 'num_layers': 6, 'dropout': 0.25},\n",
    "        {'hidden_dim': 160, 'num_layers': 3, 'dropout': 0.15}\n",
    "    ]\n",
    "    \n",
    "    for i, config in enumerate(configs):\n",
    "        print(f\"\\nðŸ”§ Training Model {i+1}/{len(configs)}\")\n",
    "        \n",
    "        model = PowerfulBlendGNN(**config).to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.7)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        best_state = None\n",
    "        patience = 0\n",
    "        \n",
    "        for epoch in range(50):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for batch in train_loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                out = model(batch.x, batch.edge_index, batch.batch, batch.u)\n",
    "                loss = F.l1_loss(out, batch.y) + 0.1 * F.mse_loss(out, batch.y)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    batch = batch.to(device)\n",
    "                    out = model(batch.x, batch.edge_index, batch.batch, batch.u)\n",
    "                    val_loss += F.l1_loss(out, batch.y).item()\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            train_loss /= len(train_loader)\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_state = model.state_dict().copy()\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience += 1\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}: Train={train_loss:.4f}, Val={val_loss:.4f}\")\n",
    "                \n",
    "            if patience >= 10:\n",
    "                break\n",
    "        \n",
    "        model.load_state_dict(best_state)\n",
    "        models.append(model)\n",
    "    \n",
    "    # Ensemble evaluation\n",
    "    print(\"\\nðŸ“Š Evaluating ensemble...\")\n",
    "    all_preds, targets = [], []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch.x, batch.edge_index, batch.batch, batch.u)\n",
    "                preds.append(out.cpu())\n",
    "        preds = torch.cat(preds).numpy()\n",
    "        all_preds.append(preds)\n",
    "    \n",
    "    # Get targets\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            targets.append(batch.y.cpu())\n",
    "    targets = torch.cat(targets).numpy()\n",
    "    \n",
    "    # Ensemble prediction\n",
    "    ensemble_preds = np.mean(all_preds, axis=0)\n",
    "    \n",
    "    mape = mean_absolute_percentage_error(targets, ensemble_preds)\n",
    "    r2 = r2_score(targets.flatten(), ensemble_preds.flatten())\n",
    "    \n",
    "    print(f\"âœ… Ensemble MAPE: {mape:.4f}\")\n",
    "    print(f\"âœ… Ensemble RÂ²: {r2:.4f}\")\n",
    "    \n",
    "    return models, create_simple_graph\n",
    "\n",
    "# Run the powerful model\n",
    "print(\"ðŸš€ Training Powerful GNN Ensemble...\")\n",
    "models, graph_creator = train_powerful_model(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/train.csv\")\n",
    "\n",
    "# Generate predictions for test set\n",
    "def generate_powerful_submission(models, graph_creator, test_csv, output_path):\n",
    "    test_df = pd.read_csv(test_csv)\n",
    "    test_graphs = [graph_creator(row, include_id=True) for _, row in tqdm(test_df.iterrows(), desc=\"Creating test graphs\")]\n",
    "    test_loader = DataLoader(test_graphs, batch_size=32)\n",
    "    \n",
    "    device = next(models[0].parameters()).device\n",
    "    all_preds = []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch.x, batch.edge_index, batch.batch, batch.u)\n",
    "                preds.append(out.cpu())\n",
    "        preds = torch.cat(preds).numpy()\n",
    "        all_preds.append(preds)\n",
    "    \n",
    "    # Ensemble prediction\n",
    "    ensemble_preds = np.mean(all_preds, axis=0)\n",
    "    \n",
    "    # Create submission\n",
    "    blend_cols = [f\"BlendProperty{i}\" for i in range(1, 11)]\n",
    "    submission_df = pd.DataFrame(ensemble_preds, columns=blend_cols)\n",
    "    \n",
    "    ids = [graph.id for graph in test_graphs]\n",
    "    submission_df.insert(0, \"ID\", ids)\n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"âœ… Powerful ensemble submission saved to {output_path}\")\n",
    "\n",
    "print(\"\\nðŸ“¤ Generating powerful submission...\")\n",
    "generate_powerful_submission(\n",
    "    models, graph_creator, \n",
    "    \"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/test.csv\",\n",
    "    \"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/powerful_submission.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b834fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ShellAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
