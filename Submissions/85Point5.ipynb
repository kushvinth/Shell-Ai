{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e5a0f1",
   "metadata": {},
   "source": [
    "# Changed RBG Scale Lenght to 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5394648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, C, Matern, WhiteKernel\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Neural Network imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Add, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, AdamW, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup comprehensive logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EnhancedModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.model_performance = {}\n",
    "        self.trained_models = {}\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def create_neural_architectures(self, input_dim, property_name):\n",
    "        \"\"\"Create multiple neural network architectures for comparison\"\"\"\n",
    "        \n",
    "        architectures = {}\n",
    "        \n",
    "        # Architecture 1: Deep Dense Network\n",
    "        model1 = Sequential([\n",
    "            Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            Dense(128, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.1),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='linear')\n",
    "        ])\n",
    "        architectures['Deep_Dense'] = model1\n",
    "        \n",
    "        # Architecture 2: Residual Network\n",
    "        def create_residual_model():\n",
    "            inputs = Input(shape=(input_dim,))\n",
    "            x = Dense(128, activation='relu')(inputs)\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "            # Residual block 1\n",
    "            shortcut = x\n",
    "            x = Dense(128, activation='relu')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dense(128, activation='linear')(x)\n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            \n",
    "            # Residual block 2\n",
    "            shortcut = x\n",
    "            x = Dense(128, activation='relu')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dense(128, activation='linear')(x)\n",
    "            x = Add()([x, shortcut])\n",
    "            x = LeakyReLU()(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            \n",
    "            # Output layers\n",
    "            x = Dense(64, activation='relu')(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            outputs = Dense(1, activation='linear')(x)\n",
    "            \n",
    "            return Model(inputs, outputs)\n",
    "        \n",
    "        architectures['Residual_Net'] = create_residual_model()\n",
    "        \n",
    "        # Architecture 3: Wide Network\n",
    "        model3 = Sequential([\n",
    "            Dense(512, activation='relu', input_shape=(input_dim,)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.4),\n",
    "            Dense(256, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation='linear')\n",
    "        ])\n",
    "        architectures['Wide_Net'] = model3\n",
    "        \n",
    "        # Architecture 4: Regularized Network\n",
    "        model4 = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(input_dim,), \n",
    "                  kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.3),\n",
    "            Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='linear')\n",
    "        ])\n",
    "        architectures['Regularized_Net'] = model4\n",
    "        \n",
    "        # Architecture 5: Ensemble-Ready Network\n",
    "        model5 = Sequential([\n",
    "            Dense(256, activation='elu', input_shape=(input_dim,)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.25),\n",
    "            Dense(128, activation='elu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.25),\n",
    "            Dense(64, activation='elu'),\n",
    "            Dropout(0.15),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='linear')\n",
    "        ])\n",
    "        architectures['Ensemble_Net'] = model5\n",
    "        \n",
    "        return architectures\n",
    "    \n",
    "    def get_traditional_models(self):\n",
    "        \"\"\"Define traditional ML models with optimized parameters\"\"\"\n",
    "        \n",
    "        models = {\n",
    "            'Enhanced_GP_RBF': make_pipeline(\n",
    "                StandardScaler(), \n",
    "                GaussianProcessRegressor(\n",
    "                    kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0) + WhiteKernel(noise_level=1e-3),\n",
    "                    n_restarts_optimizer=10, \n",
    "                    random_state=42,\n",
    "                    alpha=1e-6\n",
    "                )\n",
    "            ),\n",
    "            'Enhanced_GP_Matern': make_pipeline(\n",
    "                StandardScaler(), \n",
    "                GaussianProcessRegressor(\n",
    "                    kernel=C(1.0, (1e-3, 1e3)) * Matern(length_scale=2.0, nu=2.5) + WhiteKernel(noise_level=1e-3),\n",
    "                    n_restarts_optimizer=10, \n",
    "                    random_state=42,\n",
    "                    alpha=1e-6\n",
    "                )\n",
    "            ),\n",
    "            'Enhanced_RF': RandomForestRegressor(\n",
    "                n_estimators=200, \n",
    "                max_depth=15, \n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42, \n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'Extra_Trees': ExtraTreesRegressor(\n",
    "                n_estimators=200,\n",
    "                max_depth=15,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'Gradient_Boosting': GradientBoostingRegressor(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=8,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42\n",
    "            ),\n",
    "            'Enhanced_ElasticNet': make_pipeline(\n",
    "                StandardScaler(),\n",
    "                ElasticNet(alpha=0.5, l1_ratio=0.5, random_state=42, max_iter=2000)\n",
    "            ),\n",
    "            'Ridge_Regression': make_pipeline(\n",
    "                StandardScaler(),\n",
    "                Ridge(alpha=1.0, random_state=42)\n",
    "            ),\n",
    "            'Enhanced_SVR_RBF': make_pipeline(\n",
    "                StandardScaler(), \n",
    "                SVR(kernel='rbf', C=10.0, epsilon=0.1, gamma='scale')\n",
    "            ),\n",
    "            'Enhanced_SVR_Poly': make_pipeline(\n",
    "                StandardScaler(), \n",
    "                SVR(kernel='poly', C=1.0, epsilon=0.1, degree=3)\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        return models\n",
    "    \n",
    "    def evaluate_model_performance(self, model, X, y, model_name, property_name):\n",
    "        \"\"\"Comprehensive model evaluation with cross-validation\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Cross-validation scores\n",
    "            cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_percentage_error', n_jobs=-1)\n",
    "            cv_mape = -cv_scores.mean()\n",
    "            cv_std = cv_scores.std()\n",
    "            \n",
    "            # Train-test split for detailed metrics\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Fit and predict\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate multiple metrics\n",
    "            mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            # Comprehensive logging\n",
    "            logger.info(f\"\")\n",
    "            logger.info(f\"{'='*80}\")\n",
    "            logger.info(f\"MODEL EVALUATION: {model_name} for {property_name}\")\n",
    "            logger.info(f\"{'='*80}\")\n",
    "            logger.info(f\"Cross-Validation MAPE: {cv_mape:.4f} ¬± {cv_std:.4f}\")\n",
    "            logger.info(f\"Test Set MAPE: {mape:.4f}\")\n",
    "            logger.info(f\"Test Set MAE: {mae:.4f}\")\n",
    "            logger.info(f\"Test Set R¬≤: {r2:.4f}\")\n",
    "            logger.info(f\"{'='*80}\")\n",
    "            \n",
    "            return {\n",
    "                'cv_mape': cv_mape,\n",
    "                'cv_std': cv_std,\n",
    "                'test_mape': mape,\n",
    "                'test_mae': mae,\n",
    "                'test_r2': r2,\n",
    "                'model': model\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error evaluating {model_name} for {property_name}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def evaluate_neural_network(self, architecture, X, y, model_name, property_name):\n",
    "        \"\"\"Evaluate neural network with proper training\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Prepare data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Compile model\n",
    "            architecture.compile(\n",
    "                optimizer=Adam(learning_rate=0.001),\n",
    "                loss='mse',\n",
    "                metrics=['mae']\n",
    "            )\n",
    "            \n",
    "            # Callbacks\n",
    "            callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7)\n",
    "            ]\n",
    "            \n",
    "            # Train model\n",
    "            logger.info(f\"Training {model_name} for {property_name}...\")\n",
    "            history = architecture.fit(\n",
    "                X_train_scaled, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=200,\n",
    "                batch_size=32,\n",
    "                callbacks=callbacks,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = architecture.predict(X_test_scaled).flatten()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            # Create a pipeline for consistent interface\n",
    "            class NeuralNetworkPipeline:\n",
    "                def __init__(self, scaler, model):\n",
    "                    self.scaler = scaler\n",
    "                    self.model = model\n",
    "                \n",
    "                def fit(self, X, y):\n",
    "                    pass  # Already trained\n",
    "                \n",
    "                def predict(self, X):\n",
    "                    X_scaled = self.scaler.transform(X)\n",
    "                    return self.model.predict(X_scaled).flatten()\n",
    "            \n",
    "            pipeline = NeuralNetworkPipeline(scaler, architecture)\n",
    "            \n",
    "            # Comprehensive logging\n",
    "            logger.info(f\"\")\n",
    "            logger.info(f\"{'='*80}\")\n",
    "            logger.info(f\"NEURAL NETWORK EVALUATION: {model_name} for {property_name}\")\n",
    "            logger.info(f\"{'='*80}\")\n",
    "            logger.info(f\"Final Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "            logger.info(f\"Final Validation Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "            logger.info(f\"Test Set MAPE: {mape:.4f}\")\n",
    "            logger.info(f\"Test Set MAE: {mae:.4f}\")\n",
    "            logger.info(f\"Test Set R¬≤: {r2:.4f}\")\n",
    "            logger.info(f\"Training Epochs: {len(history.history['loss'])}\")\n",
    "            logger.info(f\"{'='*80}\")\n",
    "            \n",
    "            return {\n",
    "                'cv_mape': mape,  # Using test MAPE as proxy\n",
    "                'cv_std': 0.0,\n",
    "                'test_mape': mape,\n",
    "                'test_mae': mae,\n",
    "                'test_r2': r2,\n",
    "                'model': pipeline,\n",
    "                'history': history\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error training {model_name} for {property_name}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def get_best_model_for_property(self, X, y, property_name):\n",
    "        \"\"\"Find the best model for a specific property through comprehensive evaluation\"\"\"\n",
    "        \n",
    "        logger.info(f\"\\nüöÄ Starting comprehensive model evaluation for {property_name}\")\n",
    "        logger.info(f\"Data shape: {X.shape}, Target shape: {y.shape}\")\n",
    "        \n",
    "        all_results = {}\n",
    "        \n",
    "        # Evaluate traditional models\n",
    "        logger.info(f\"\\nüìä Evaluating Traditional ML Models for {property_name}\")\n",
    "        traditional_models = self.get_traditional_models()\n",
    "        \n",
    "        for model_name, model in traditional_models.items():\n",
    "            logger.info(f\"\\nEvaluating {model_name}...\")\n",
    "            result = self.evaluate_model_performance(model, X, y, model_name, property_name)\n",
    "            if result:\n",
    "                all_results[model_name] = result\n",
    "        \n",
    "        # Evaluate neural networks\n",
    "        logger.info(f\"\\nüß† Evaluating Neural Network Architectures for {property_name}\")\n",
    "        neural_architectures = self.create_neural_architectures(X.shape[1], property_name)\n",
    "        \n",
    "        for arch_name, architecture in neural_architectures.items():\n",
    "            logger.info(f\"\\nEvaluating {arch_name}...\")\n",
    "            result = self.evaluate_neural_network(architecture, X, y, arch_name, property_name)\n",
    "            if result:\n",
    "                all_results[arch_name] = result\n",
    "        \n",
    "        # Find best model\n",
    "        if all_results:\n",
    "            best_model_name = min(all_results.keys(), key=lambda k: all_results[k]['test_mape'])\n",
    "            best_result = all_results[best_model_name]\n",
    "            \n",
    "            logger.info(f\"\\nüèÜ BEST MODEL FOR {property_name}: {best_model_name}\")\n",
    "            logger.info(f\"Best Test MAPE: {best_result['test_mape']:.4f}\")\n",
    "            logger.info(f\"Best Test R¬≤: {best_result['test_r2']:.4f}\")\n",
    "            \n",
    "            # Store results\n",
    "            self.model_performance[property_name] = {\n",
    "                'best_model': best_model_name,\n",
    "                'all_results': all_results,\n",
    "                'best_performance': best_result\n",
    "            }\n",
    "            \n",
    "            return best_result['model'], best_model_name, best_result\n",
    "        \n",
    "        else:\n",
    "            logger.error(f\"No models successfully trained for {property_name}\")\n",
    "            return None, None, None\n",
    "\n",
    "# Initialize the enhanced trainer\n",
    "trainer = EnhancedModelTrainer()\n",
    "\n",
    "# Load data\n",
    "logger.info(\"Loading training and test data...\")\n",
    "try:\n",
    "    # Load training data\n",
    "    df = pd.read_csv(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/train.csv\")\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/test.csv\")\n",
    "    sample_submission = pd.read_csv(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/sample_solution.csv\")\n",
    "    \n",
    "    test_ids = test_df['ID']\n",
    "    test_df_features = test_df.drop(columns=['ID'])\n",
    "    \n",
    "    logger.info(f\"Training data shape: {df.shape}\")\n",
    "    logger.info(f\"Test data shape: {test_df.shape}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"Data files not found: {e}\")\n",
    "    print(\"Please ensure all data files are in the correct location.\")\n",
    "\n",
    "# Process each property\n",
    "if 'df' in locals() and 'test_df_features' in locals():\n",
    "    final_predictions = {}\n",
    "    submission_df = sample_submission.copy()\n",
    "    \n",
    "    # Log overall process start\n",
    "    logger.info(f\"\\nüéØ STARTING COMPREHENSIVE MODEL TRAINING FOR ALL PROPERTIES\")\n",
    "    logger.info(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    logger.info(f\"{'='*100}\")\n",
    "    \n",
    "    for i in range(1, 11):\n",
    "        property_name = f'BlendProperty{i}'\n",
    "        \n",
    "        logger.info(f\"\\n\\nüîÑ PROCESSING {property_name} ({i}/10)\")\n",
    "        logger.info(f\"{'='*100}\")\n",
    "        \n",
    "        # Define features for this property\n",
    "        features = ['Component1_fraction', 'Component2_fraction', 'Component3_fraction',\n",
    "                   'Component4_fraction', 'Component5_fraction'] + \\\n",
    "                  [f'Component{j}_Property{i}' for j in range(1, 6)]\n",
    "        \n",
    "        # Extract training data\n",
    "        X = df[features]\n",
    "        y = df[property_name]\n",
    "        \n",
    "        logger.info(f\"Features for {property_name}: {len(features)} features\")\n",
    "        logger.info(f\"Target statistics - Mean: {y.mean():.4f}, Std: {y.std():.4f}\")\n",
    "        \n",
    "        # Find best model\n",
    "        start_time = time.time()\n",
    "        best_model, best_model_name, best_result = trainer.get_best_model_for_property(X, y, property_name)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        if best_model and best_model_name:\n",
    "            # Retrain on full dataset\n",
    "            logger.info(f\"\\nüîß Retraining {best_model_name} on full dataset for {property_name}...\")\n",
    "            best_model.fit(X, y)\n",
    "            \n",
    "            # Make predictions\n",
    "            test_predictions = best_model.predict(test_df_features[features])\n",
    "            submission_df[property_name] = test_predictions\n",
    "            \n",
    "            # Store results\n",
    "            final_predictions[property_name] = {\n",
    "                'model_name': best_model_name,\n",
    "                'model': best_model,\n",
    "                'performance': best_result,\n",
    "                'training_time': training_time,\n",
    "                'predictions': test_predictions\n",
    "            }\n",
    "            \n",
    "            # Final logging for this property\n",
    "            logger.info(f\"‚úÖ {property_name} COMPLETE\")\n",
    "            logger.info(f\"Best Model: {best_model_name}\")\n",
    "            logger.info(f\"Performance: MAPE={best_result['test_mape']:.4f}, R¬≤={best_result['test_r2']:.4f}\")\n",
    "            logger.info(f\"Training Time: {training_time:.2f} seconds\")\n",
    "            logger.info(f\"Prediction Range: [{test_predictions.min():.4f}, {test_predictions.max():.4f}]\")\n",
    "            \n",
    "        else:\n",
    "            logger.error(f\"‚ùå Failed to train models for {property_name}\")\n",
    "    \n",
    "    # Save final submission\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    submission_filename = f'enhanced_submission_{timestamp}.csv'\n",
    "    submission_df.to_csv(submission_filename, index=False)\n",
    "    \n",
    "    # Final summary logging\n",
    "    logger.info(f\"\\n\\nüéâ TRAINING COMPLETE FOR ALL PROPERTIES\")\n",
    "    logger.info(f\"{'='*100}\")\n",
    "    logger.info(f\"Submission saved as: {submission_filename}\")\n",
    "    \n",
    "    # Print summary table\n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(f\"FINAL MODEL SUMMARY\")\n",
    "    print(f\"{'='*120}\")\n",
    "    print(f\"{'Property':<15} {'Best Model':<20} {'MAPE':<10} {'R¬≤':<10} {'Time (s)':<10}\")\n",
    "    print(f\"{'-'*120}\")\n",
    "    \n",
    "    for prop, details in final_predictions.items():\n",
    "        print(f\"{prop:<15} {details['model_name']:<20} {details['performance']['test_mape']:<10.4f} \"\n",
    "              f\"{details['performance']['test_r2']:<10.4f} {details['training_time']:<10.2f}\")\n",
    "    \n",
    "    print(f\"{'='*120}\")\n",
    "    print(f\"Enhanced submission file saved: {submission_filename}\")\n",
    "\n",
    "else:\n",
    "    logger.error(\"Failed to load required data files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Model Analysis and Ensemble Generation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import learning_curve\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "class ModelAnalyzer:\n",
    "    def __init__(self, trainer):\n",
    "        self.trainer = trainer\n",
    "        \n",
    "    def plot_performance_comparison(self):\n",
    "        \"\"\"Create comprehensive performance visualizations\"\"\"\n",
    "        \n",
    "        if not self.trainer.model_performance:\n",
    "            logger.warning(\"No model performance data available for plotting\")\n",
    "            return\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        properties = []\n",
    "        models = []\n",
    "        mape_scores = []\n",
    "        r2_scores = []\n",
    "        \n",
    "        for prop, data in self.trainer.model_performance.items():\n",
    "            for model_name, results in data['all_results'].items():\n",
    "                properties.append(prop)\n",
    "                models.append(model_name)\n",
    "                mape_scores.append(results['test_mape'])\n",
    "                r2_scores.append(results['test_r2'])\n",
    "        \n",
    "        # Create DataFrame for plotting\n",
    "        plot_df = pd.DataFrame({\n",
    "            'Property': properties,\n",
    "            'Model': models,\n",
    "            'MAPE': mape_scores,\n",
    "            'R2': r2_scores\n",
    "        })\n",
    "        \n",
    "        # Plot 1: MAPE comparison across properties\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        pivot_mape = plot_df.pivot(index='Property', columns='Model', values='MAPE')\n",
    "        sns.heatmap(pivot_mape, annot=True, fmt='.3f', cmap='RdYlBu_r')\n",
    "        plt.title('MAPE Scores by Property and Model')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Plot 2: R¬≤ comparison across properties\n",
    "        plt.subplot(2, 2, 2)\n",
    "        pivot_r2 = plot_df.pivot(index='Property', columns='Model', values='R2')\n",
    "        sns.heatmap(pivot_r2, annot=True, fmt='.3f', cmap='RdYlBu')\n",
    "        plt.title('R¬≤ Scores by Property and Model')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Plot 3: Best model distribution\n",
    "        plt.subplot(2, 2, 3)\n",
    "        best_models = [data['best_model'] for data in self.trainer.model_performance.values()]\n",
    "        model_counts = pd.Series(best_models).value_counts()\n",
    "        plt.pie(model_counts.values, labels=model_counts.index, autopct='%1.1f%%')\n",
    "        plt.title('Distribution of Best Models')\n",
    "        \n",
    "        # Plot 4: Average performance by model type\n",
    "        plt.subplot(2, 2, 4)\n",
    "        avg_performance = plot_df.groupby('Model')[['MAPE', 'R2']].mean().sort_values('MAPE')\n",
    "        \n",
    "        x = range(len(avg_performance))\n",
    "        plt.bar(x, avg_performance['MAPE'], alpha=0.7, label='MAPE')\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('Average MAPE')\n",
    "        plt.title('Average Performance by Model Type')\n",
    "        plt.xticks(x, avg_performance.index, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return plot_df\n",
    "    \n",
    "    def create_ensemble_models(self, X_dict, y_dict, test_features):\n",
    "        \"\"\"Create ensemble models for improved performance\"\"\"\n",
    "        \n",
    "        logger.info(\"\\nüéØ Creating Ensemble Models\")\n",
    "        ensemble_predictions = {}\n",
    "        \n",
    "        for i in range(1, 11):\n",
    "            property_name = f'BlendProperty{i}'\n",
    "            \n",
    "            if property_name not in self.trainer.model_performance:\n",
    "                continue\n",
    "                \n",
    "            logger.info(f\"\\nCreating ensemble for {property_name}...\")\n",
    "            \n",
    "            # Get top 3 models for this property\n",
    "            all_results = self.trainer.model_performance[property_name]['all_results']\n",
    "            sorted_models = sorted(all_results.items(), key=lambda x: x[1]['test_mape'])[:3]\n",
    "            \n",
    "            ensemble_models = []\n",
    "            model_names = []\n",
    "            \n",
    "            for model_name, results in sorted_models:\n",
    "                if 'Net' not in model_name:  # Exclude neural networks from voting regressor\n",
    "                    ensemble_models.append((model_name, results['model']))\n",
    "                    model_names.append(model_name)\n",
    "            \n",
    "            if len(ensemble_models) >= 2:\n",
    "                # Create voting regressor\n",
    "                voting_regressor = VotingRegressor(ensemble_models)\n",
    "                \n",
    "                # Train on full dataset\n",
    "                X = X_dict[property_name]\n",
    "                y = y_dict[property_name]\n",
    "                voting_regressor.fit(X, y)\n",
    "                \n",
    "                # Make predictions\n",
    "                ensemble_pred = voting_regressor.predict(test_features[property_name])\n",
    "                ensemble_predictions[property_name] = ensemble_pred\n",
    "                \n",
    "                logger.info(f\"Ensemble for {property_name}: {model_names}\")\n",
    "                logger.info(f\"Prediction range: [{ensemble_pred.min():.4f}, {ensemble_pred.max():.4f}]\")\n",
    "            \n",
    "            else:\n",
    "                logger.info(f\"Not enough suitable models for ensemble in {property_name}\")\n",
    "        \n",
    "        return ensemble_predictions\n",
    "    \n",
    "    def save_model_artifacts(self, final_predictions, ensemble_predictions=None):\n",
    "        \"\"\"Save all trained models and metadata\"\"\"\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Save model performance summary\n",
    "        performance_summary = {}\n",
    "        for prop, data in self.trainer.model_performance.items():\n",
    "            performance_summary[prop] = {\n",
    "                'best_model': data['best_model'],\n",
    "                'best_mape': data['best_performance']['test_mape'],\n",
    "                'best_r2': data['best_performance']['test_r2'],\n",
    "                'all_models_mape': {name: results['test_mape'] \n",
    "                                   for name, results in data['all_results'].items()}\n",
    "            }\n",
    "        \n",
    "        # Save performance summary as JSON\n",
    "        with open(f'model_performance_summary_{timestamp}.json', 'w') as f:\n",
    "            json.dump(performance_summary, f, indent=2)\n",
    "        \n",
    "        # Save individual models (non-neural network ones)\n",
    "        saved_models = {}\n",
    "        for prop, details in final_predictions.items():\n",
    "            model_name = details['model_name']\n",
    "            if 'Net' not in model_name:  # Traditional ML models\n",
    "                try:\n",
    "                    model_filename = f'model_{prop}_{model_name}_{timestamp}.pkl'\n",
    "                    with open(model_filename, 'wb') as f:\n",
    "                        pickle.dump(details['model'], f)\n",
    "                    saved_models[prop] = model_filename\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Could not save model for {prop}: {e}\")\n",
    "        \n",
    "        logger.info(f\"\\nüíæ Model artifacts saved:\")\n",
    "        logger.info(f\"Performance summary: model_performance_summary_{timestamp}.json\")\n",
    "        logger.info(f\"Saved {len(saved_models)} traditional ML models\")\n",
    "        \n",
    "        return performance_summary\n",
    "\n",
    "# Run advanced analysis if models have been trained\n",
    "if 'trainer' in locals() and trainer.model_performance:\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = ModelAnalyzer(trainer)\n",
    "    \n",
    "    # Create performance visualizations\n",
    "    logger.info(\"\\nüìä Creating performance visualizations...\")\n",
    "    plot_data = analyzer.plot_performance_comparison()\n",
    "    \n",
    "    # Create ensemble models if we have trained models\n",
    "    if 'final_predictions' in locals():\n",
    "        logger.info(\"\\nüîÆ Creating ensemble predictions...\")\n",
    "        \n",
    "        # Prepare data dictionaries for ensemble\n",
    "        X_dict = {}\n",
    "        y_dict = {}\n",
    "        test_features_dict = {}\n",
    "        \n",
    "        for i in range(1, 11):\n",
    "            property_name = f'BlendProperty{i}'\n",
    "            features = ['Component1_fraction', 'Component2_fraction', 'Component3_fraction',\n",
    "                       'Component4_fraction', 'Component5_fraction'] + \\\n",
    "                      [f'Component{j}_Property{i}' for j in range(1, 6)]\n",
    "            \n",
    "            X_dict[property_name] = df[features]\n",
    "            y_dict[property_name] = df[property_name]\n",
    "            test_features_dict[property_name] = test_df_features[features]\n",
    "        \n",
    "        # Create ensemble predictions\n",
    "        ensemble_predictions = analyzer.create_ensemble_models(X_dict, y_dict, test_features_dict)\n",
    "        \n",
    "        # Create ensemble submission if we have predictions\n",
    "        if ensemble_predictions:\n",
    "            ensemble_submission = sample_submission.copy()\n",
    "            for prop, predictions in ensemble_predictions.items():\n",
    "                ensemble_submission[prop] = predictions\n",
    "            \n",
    "            ensemble_filename = f'ensemble_submission_{timestamp}.csv'\n",
    "            ensemble_submission.to_csv(ensemble_filename, index=False)\n",
    "            logger.info(f\"Ensemble submission saved: {ensemble_filename}\")\n",
    "        \n",
    "        # Save model artifacts\n",
    "        logger.info(\"\\nüíæ Saving model artifacts...\")\n",
    "        performance_summary = analyzer.save_model_artifacts(final_predictions, ensemble_predictions)\n",
    "        \n",
    "        # Print final comprehensive summary\n",
    "        print(f\"\\n{'='*140}\")\n",
    "        print(f\"COMPREHENSIVE MODEL ANALYSIS COMPLETE\")\n",
    "        print(f\"{'='*140}\")\n",
    "        print(f\"üìä Performance data plotted and analyzed\")\n",
    "        print(f\"üîÆ Ensemble models created for applicable properties\")\n",
    "        print(f\"üíæ Model artifacts saved with timestamp: {timestamp}\")\n",
    "        print(f\"üìà Best overall models by property:\")\n",
    "        \n",
    "        for prop, summary in performance_summary.items():\n",
    "            print(f\"   {prop:<15}: {summary['best_model']:<20} (MAPE: {summary['best_mape']:.4f})\")\n",
    "        \n",
    "        print(f\"{'='*140}\")\n",
    "\n",
    "else:\n",
    "    logger.info(\"No trained models available for advanced analysis\")\n",
    "    print(\"Please run the model training cell first to generate models for analysis.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
