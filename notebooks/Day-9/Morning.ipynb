{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717fb478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge, ElasticNet, HuberRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel as C\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "#########FIX###########\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# n_splits = 5\n",
    "#######################\n",
    "\n",
    "# Load Data\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/train.csv')\n",
    "test = pd.read_csv('/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b823031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating breakthrough features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'harmonic_mean_prop{j}'] = 1 / harmonic_mean\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'geometric_mean_prop{j}'] = np.exp(log_geo_mean)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'dominant_prop{j}'] = df.apply(lambda row:\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'blend_balance_prop{j}'] = 1 - df[frac_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'blend_diversity_prop{j}'] = df[frac_cols].std(axis=1) / (df[frac_cols].mean(axis=1) + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_sum'] = df[frac_cols].sum(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_std'] = df[frac_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_skew'] = df[frac_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_kurtosis'] = df[frac_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_entropy'] = -sum(df[f'Component{i}_fraction'] * np.log(df[f'Component{i}_fraction'] + 1e-8) for i in range(1, 6))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:124: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_gini'] = 1 - sum(df[f'Component{i}_fraction'] ** 2 for i in range(1, 6))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_mean_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'weighted_var_prop{j}'] = sum(\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'harmonic_mean_prop{j}'] = 1 / harmonic_mean\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'geometric_mean_prop{j}'] = np.exp(log_geo_mean)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'dominant_prop{j}'] = df.apply(lambda row:\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'blend_balance_prop{j}'] = 1 - df[frac_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'blend_diversity_prop{j}'] = df[frac_cols].std(axis=1) / (df[frac_cols].mean(axis=1) + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ron_like_blend_prop{j}'] = ron_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'density_blend_prop{j}'] = density_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'rvp_blend_prop{j}'] = rvp_blend\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_sum'] = df[frac_cols].sum(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_std'] = df[frac_cols].std(axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_skew'] = df[frac_cols].apply(lambda row: skew(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_kurtosis'] = df[frac_cols].apply(lambda row: kurtosis(row), axis=1)\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_entropy'] = -sum(df[f'Component{i}_fraction'] * np.log(df[f'Component{i}_fraction'] + 1e-8) for i in range(1, 6))\n",
      "/var/folders/pj/jwdq4dd92f54s4h77g71lj8r0000gn/T/ipykernel_85193/1698061779.py:124: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['frac_gini'] = 1 - sum(df[f'Component{i}_fraction'] ** 2 for i in range(1, 6))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling NaN values...\n",
      "Handling NaN values...\n",
      "Performing feature selection...\n",
      "Original features: 433\n",
      "Selected features: 217\n",
      "Training Breakthrough Ensemble...\n",
      "Features: 433 (selected: 217)\n",
      "\n",
      "Training for BlendProperty1...\n",
      "Original features: 433\n",
      "Selected features: 217\n",
      "Training Breakthrough Ensemble...\n",
      "Features: 433 (selected: 217)\n",
      "\n",
      "Training for BlendProperty1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:450: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 6.5194 (weight: 0.000)\n",
      "Extra Trees MAPE: 7.7260 (weight: 0.000)\n",
      "Gradient Boosting MAPE: 2.2382 (weight: 0.000)\n",
      "Ridge MAPE: 0.3504 (weight: 0.033)\n",
      "Elastic Net MAPE: 6.8524 (weight: 0.000)\n",
      "Huber MAPE: 2.8509 (weight: 0.000)\n",
      "Gaussian Process MAPE: 0.0120 (weight: 0.967)\n",
      "Ensemble MAPE: 0.0223\n",
      "\n",
      "Training for BlendProperty2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 1.7459 (weight: 0.000)\n",
      "Extra Trees MAPE: 1.5134 (weight: 0.000)\n",
      "Gradient Boosting MAPE: 1.5687 (weight: 0.000)\n",
      "Ridge MAPE: 0.2463 (weight: 0.998)\n",
      "Elastic Net MAPE: 1.8149 (weight: 0.000)\n",
      "Huber MAPE: 2.0006 (weight: 0.000)\n",
      "Gaussian Process MAPE: 0.8464 (weight: 0.002)\n",
      "Ensemble MAPE: 0.2456\n",
      "\n",
      "Training for BlendProperty3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 1.7066 (weight: 0.003)\n",
      "Extra Trees MAPE: 1.4699 (weight: 0.030)\n",
      "Gradient Boosting MAPE: 1.6071 (weight: 0.008)\n",
      "Ridge MAPE: 1.1249 (weight: 0.935)\n",
      "Elastic Net MAPE: 1.8269 (weight: 0.001)\n",
      "Huber MAPE: 1.8455 (weight: 0.001)\n",
      "Gaussian Process MAPE: 1.4935 (weight: 0.023)\n",
      "Ensemble MAPE: 1.0882\n",
      "\n",
      "Training for BlendProperty4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 2.1230 (weight: 0.000)\n",
      "Extra Trees MAPE: 1.5719 (weight: 0.000)\n",
      "Gradient Boosting MAPE: 2.0651 (weight: 0.000)\n",
      "Ridge MAPE: 0.4311 (weight: 0.998)\n",
      "Elastic Net MAPE: 1.6498 (weight: 0.000)\n",
      "Huber MAPE: 2.4996 (weight: 0.000)\n",
      "Gaussian Process MAPE: 1.0392 (weight: 0.002)\n",
      "Ensemble MAPE: 0.4308\n",
      "\n",
      "Training for BlendProperty5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 0.0659 (weight: 0.454)\n",
      "Extra Trees MAPE: 0.0806 (weight: 0.391)\n",
      "Gradient Boosting MAPE: 0.1733 (weight: 0.155)\n",
      "Ridge MAPE: 4.3307 (weight: 0.000)\n",
      "Elastic Net MAPE: 1.8788 (weight: 0.000)\n",
      "Huber MAPE: 2.8792 (weight: 0.000)\n",
      "Gaussian Process MAPE: 3.5955 (weight: 0.000)\n",
      "Ensemble MAPE: 0.0748\n",
      "\n",
      "Training for BlendProperty6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 1.3170 (weight: 0.000)\n",
      "Extra Trees MAPE: 0.9869 (weight: 0.000)\n",
      "Gradient Boosting MAPE: 1.3656 (weight: 0.000)\n",
      "Ridge MAPE: 0.0848 (weight: 1.000)\n",
      "Elastic Net MAPE: 0.9801 (weight: 0.000)\n",
      "Huber MAPE: 1.5918 (weight: 0.000)\n",
      "Gaussian Process MAPE: 1.7208 (weight: 0.000)\n",
      "Ensemble MAPE: 0.0848\n",
      "\n",
      "Training for BlendProperty7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 2.9202 (weight: 0.000)\n",
      "Extra Trees MAPE: 2.6220 (weight: 0.000)\n",
      "Gradient Boosting MAPE: 2.1478 (weight: 0.033)\n",
      "Ridge MAPE: 1.8113 (weight: 0.966)\n",
      "Elastic Net MAPE: 2.7718 (weight: 0.000)\n",
      "Huber MAPE: 2.7670 (weight: 0.000)\n",
      "Gaussian Process MAPE: 2.7675 (weight: 0.000)\n",
      "Ensemble MAPE: 1.8020\n",
      "\n",
      "Training for BlendProperty8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 1.9474 (weight: 0.000)\n",
      "Extra Trees MAPE: 1.8058 (weight: 0.000)\n",
      "Gradient Boosting MAPE: 1.8550 (weight: 0.000)\n",
      "Ridge MAPE: 0.8190 (weight: 0.993)\n",
      "Elastic Net MAPE: 1.3192 (weight: 0.007)\n",
      "Huber MAPE: 1.8408 (weight: 0.000)\n",
      "Gaussian Process MAPE: 2.2157 (weight: 0.000)\n",
      "Ensemble MAPE: 0.8171\n",
      "\n",
      "Training for BlendProperty9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 1.9401 (weight: 0.009)\n",
      "Extra Trees MAPE: 1.4723 (weight: 0.980)\n",
      "Gradient Boosting MAPE: 2.5705 (weight: 0.000)\n",
      "Ridge MAPE: 2.0976 (weight: 0.002)\n",
      "Elastic Net MAPE: 2.3398 (weight: 0.000)\n",
      "Huber MAPE: 1.9415 (weight: 0.009)\n",
      "Gaussian Process MAPE: 2.6391 (weight: 0.000)\n",
      "Ensemble MAPE: 1.4664\n",
      "\n",
      "Training for BlendProperty10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE: 1.4180 (weight: 0.000)\n",
      "Extra Trees MAPE: 1.2873 (weight: 0.000)\n",
      "Gradient Boosting MAPE: 1.3009 (weight: 0.000)\n",
      "Ridge MAPE: 0.1275 (weight: 1.000)\n",
      "Elastic Net MAPE: 2.1779 (weight: 0.000)\n",
      "Huber MAPE: 2.1567 (weight: 0.000)\n",
      "Gaussian Process MAPE: 1.9960 (weight: 0.000)\n",
      "Ensemble MAPE: 0.1275\n",
      "\n",
      "Training Stacking Regressor...\n",
      "\n",
      "Training Stacking Regressor for BlendProperty1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor MAPE for BlendProperty1: 0.6251\n",
      "\n",
      "Training Stacking Regressor for BlendProperty2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor MAPE for BlendProperty2: 0.7069\n",
      "\n",
      "Training Stacking Regressor for BlendProperty3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor MAPE for BlendProperty3: 0.7493\n",
      "\n",
      "Training Stacking Regressor for BlendProperty4...\n",
      "Stacking Regressor MAPE for BlendProperty4: 0.9815\n",
      "\n",
      "Training Stacking Regressor for BlendProperty5...\n",
      "Stacking Regressor MAPE for BlendProperty5: 0.9218\n",
      "\n",
      "Training Stacking Regressor for BlendProperty6...\n",
      "Stacking Regressor MAPE for BlendProperty6: 0.8721\n",
      "\n",
      "Training Stacking Regressor for BlendProperty7...\n",
      "Stacking Regressor MAPE for BlendProperty7: 1.5830\n",
      "\n",
      "Training Stacking Regressor for BlendProperty8...\n",
      "Stacking Regressor MAPE for BlendProperty8: 0.5501\n",
      "\n",
      "Training Stacking Regressor for BlendProperty9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor MAPE for BlendProperty9: 0.8997\n",
      "\n",
      "Training Stacking Regressor for BlendProperty10...\n",
      "Stacking Regressor MAPE for BlendProperty10: 1.2199\n",
      "\n",
      "Submission file created: submission_breakthrough_90plus_with_gp_stacking.csv\n",
      "\n",
      "Breakthrough Ensemble Summary:\n",
      "Features: 433 (selected: 217)\n",
      "Cross-validation: 5-fold\n",
      "Models: Random Forest, Extra Trees, Gradient Boosting, Ridge, Elastic Net, Huber, Gaussian Process\n",
      "Ensemble: Exponential weighting based on validation performance\n",
      "Stacking: Additional Stacking Regressor with Ridge meta-learner\n",
      "Final: Combined ensemble (70%) + stacking (30%) predictions\n",
      "Scaling: Robust and Standard scaling for different models\n",
      "Target: 90+ score with breakthrough features, GP regressor, and advanced stacking ensemble\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Breakthrough Feature Engineering\n",
    "def create_breakthrough_features(df, pca_model=None, scaler=None, fit_transformers=True):\n",
    "    features = [f'Component{i}_fraction' for i in range(1, 6)]\n",
    "    features += [f'Component{i}_Property{j}' for i in range(1, 6) for j in range(1, 11)]\n",
    "\n",
    "    # Enhanced interaction features with non-linear transformations\n",
    "    for i in range(1, 6):\n",
    "        for j in range(1, 11):\n",
    "            df[f'frac{i}_prop{j}'] = df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}']\n",
    "            df[f'frac{i}_prop{j}_sqrt'] = df[f'Component{i}_fraction'] * np.sqrt(np.abs(df[f'Component{i}_Property{j}']))\n",
    "            df[f'frac{i}_prop{j}_log'] = df[f'Component{i}_fraction'] * np.log(np.abs(df[f'Component{i}_Property{j}']) + 1)\n",
    "            df[f'frac{i}_prop{j}_square'] = df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] ** 2)\n",
    "            features.extend([f'frac{i}_prop{j}', f'frac{i}_prop{j}_sqrt', f'frac{i}_prop{j}_log', f'frac{i}_prop{j}_square'])\n",
    "\n",
    "    # Advanced weighted features with multiple aggregation methods\n",
    "    for j in range(1, 11):\n",
    "        prop_cols = [f'Component{i}_Property{j}' for i in range(1, 6)]\n",
    "        frac_cols = [f'Component{i}_fraction' for i in range(1, 6)]\n",
    "\n",
    "        # Multiple weighted aggregations\n",
    "        df[f'weighted_mean_prop{j}'] = sum(\n",
    "            df[f'Component{i}_fraction'] * df[f'Component{i}_Property{j}'] for i in range(1, 6)\n",
    "        )\n",
    "        mean = df[f'weighted_mean_prop{j}']\n",
    "        df[f'weighted_var_prop{j}'] = sum(\n",
    "            df[f'Component{i}_fraction'] * (df[f'Component{i}_Property{j}'] - mean) ** 2 for i in range(1, 6)\n",
    "        )\n",
    "\n",
    "    # Harmonic mean (important for fuel properties)\n",
    "    safe_props = [np.maximum(df[f'Component{i}_Property{j}'], 1e-6) for i in range(1, 6)]\n",
    "    harmonic_mean = sum(df[f'Component{i}_fraction'] / safe_props[i-1] for i in range(1, 6))\n",
    "    df[f'harmonic_mean_prop{j}'] = 1 / harmonic_mean\n",
    "\n",
    "    # Geometric mean (for multiplicative properties)\n",
    "    log_geo_mean = sum(df[f'Component{i}_fraction'] * np.log(safe_props[i-1]) for i in range(1, 6))\n",
    "    df[f'geometric_mean_prop{j}'] = np.exp(log_geo_mean)\n",
    "\n",
    "    # Component dominance with ranking\n",
    "    frac_array = np.array([df[f'Component{i}_fraction'] for i in range(1, 6)])\n",
    "    dominant_idx = np.argmax(frac_array, axis=0)\n",
    "    df[f'dominant_prop{j}'] = df.apply(lambda row:\n",
    "        row[f'Component{dominant_idx[row.name] + 1}_Property{j}'], axis=1)\n",
    "\n",
    "    # Blend balance and diversity\n",
    "    frac_cols = [f'Component{i}_fraction' for i in range(1, 6)]\n",
    "    df[f'blend_balance_prop{j}'] = 1 - df[frac_cols].std(axis=1)\n",
    "    df[f'blend_diversity_prop{j}'] = df[frac_cols].std(axis=1) / (df[frac_cols].mean(axis=1) + 1e-8)\n",
    "\n",
    "    # Advanced statistics\n",
    "    for j in range(1, 11):\n",
    "        prop_cols = [f'Component{i}_Property{j}' for i in range(1, 6)]\n",
    "        df[f'min_prop{j}'] = df[prop_cols].min(axis=1)\n",
    "        df[f'max_prop{j}'] = df[prop_cols].max(axis=1)\n",
    "        df[f'mean_prop{j}'] = df[prop_cols].mean(axis=1)\n",
    "        df[f'std_prop{j}'] = df[prop_cols].std(axis=1)\n",
    "        df[f'median_prop{j}'] = df[prop_cols].median(axis=1)\n",
    "        df[f'skew_prop{j}'] = df[prop_cols].apply(lambda row: skew(row), axis=1)\n",
    "        df[f'kurtosis_prop{j}'] = df[prop_cols].apply(lambda row: kurtosis(row), axis=1)\n",
    "        df[f'range_prop{j}'] = df[f'max_prop{j}'] - df[f'min_prop{j}']\n",
    "        df[f'iqr_prop{j}'] = df[prop_cols].quantile(0.75, axis=1) - df[prop_cols].quantile(0.25, axis=1)\n",
    "\n",
    "        features.extend([\n",
    "            f'min_prop{j}', f'max_prop{j}', f'mean_prop{j}',\n",
    "            f'std_prop{j}', f'median_prop{j}', f'skew_prop{j}', f'kurtosis_prop{j}',\n",
    "            f'range_prop{j}', f'iqr_prop{j}'\n",
    "        ])\n",
    "\n",
    "\n",
    "    # Shell-specific advanced features\n",
    "    for j in range(1, 11):\n",
    "        fractions = [df[f'Component{i}_fraction'] for i in range(1, 6)]\n",
    "        props = [df[f'Component{i}_Property{j}'] for i in range(1, 6)]\n",
    "        safe_props = [np.maximum(p, 1e-6) for p in props]\n",
    "\n",
    "        # RON-like blending (non-linear octane)\n",
    "        ron_blend = sum(f * (r ** 1.5) for f, r in zip(fractions, safe_props)) ** (1 / 1.5)\n",
    "        df[f'ron_like_blend_prop{j}'] = ron_blend\n",
    "\n",
    "        # Viscosity-like blending (logarithmic)\n",
    "        log_visc_blend = sum(f * np.log(r) for f, r in zip(fractions, safe_props))\n",
    "        df[f'log_visc_blend_prop{j}'] = log_visc_blend\n",
    "\n",
    "        # Density-like blending (linear but with corrections)\n",
    "        density_blend = sum(f * r for f, r in zip(fractions, safe_props))\n",
    "        df[f'density_blend_prop{j}'] = density_blend\n",
    "\n",
    "    # Reid vapor pressure-like (exponential)\n",
    "        rvp_blend = sum(f * np.exp(r / 100) for f, r in zip(fractions, safe_props))\n",
    "        df[f'rvp_blend_prop{j}'] = rvp_blend\n",
    "\n",
    "        features.extend([\n",
    "            f'ron_like_blend_prop{j}', f'log_visc_blend_prop{j}',\n",
    "            f'density_blend_prop{j}', f'rvp_blend_prop{j}'\n",
    "        ])\n",
    "\n",
    "    # Cross-property interactions (most important combinations)\n",
    "    for j1 in range(1, 6):\n",
    "        for j2 in range(j1 + 1, 7):\n",
    "            df[f'prop{j1}_prop{j2}_interaction'] = df[f'weighted_mean_prop{j1}'] * df[f'weighted_mean_prop{j2}']\n",
    "            df[f'prop{j1}_prop{j2}_ratio'] = df[f'weighted_mean_prop{j1}'] / (df[f'weighted_mean_prop{j2}'] + 1e-8)\n",
    "            features.extend([f'prop{j1}_prop{j2}_interaction', f'prop{j1}_prop{j2}_ratio'])\n",
    "\n",
    "    # Enhanced PCA with more components\n",
    "    prop_features = [f'Component{i}_Property{j}' for i in range(1, 6) for j in range(1, 11)]\n",
    "    if fit_transformers:\n",
    "        pca = PCA(n_components=12, random_state=42)\n",
    "        pca_feats = pca.fit_transform(df[prop_features])\n",
    "    else:\n",
    "        pca = pca_model\n",
    "        pca_feats = pca.transform(df[prop_features])\n",
    "\n",
    "\n",
    "    for k in range(12):\n",
    "        df[f'pca_prop_{k+1}'] = pca_feats[:, k]\n",
    "        features.append(f'pca_prop_{k+1}')\n",
    "\n",
    "    # Fraction-based advanced features\n",
    "    frac_cols = [f'Component{i}_fraction' for i in range(1, 6)]\n",
    "    df['frac_sum'] = df[frac_cols].sum(axis=1)\n",
    "    df['frac_std'] = df[frac_cols].std(axis=1)\n",
    "    df['frac_skew'] = df[frac_cols].apply(lambda row: skew(row), axis=1)\n",
    "    df['frac_kurtosis'] = df[frac_cols].apply(lambda row: kurtosis(row), axis=1)\n",
    "    df['frac_entropy'] = -sum(df[f'Component{i}_fraction'] * np.log(df[f'Component{i}_fraction'] + 1e-8) for i in range(1, 6))\n",
    "    df['frac_gini'] = 1 - sum(df[f'Component{i}_fraction'] ** 2 for i in range(1, 6))\n",
    "\n",
    "    features.extend(['frac_sum', 'frac_std', 'frac_skew', 'frac_kurtosis', 'frac_entropy', 'frac_gini'])\n",
    "\n",
    "    return df, features, pca\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"Creating breakthrough features...\")\n",
    "train, feat_cols, pca_model = create_breakthrough_features(train, fit_transformers=True)\n",
    "test, _, _ = create_breakthrough_features(test, pca_model=pca_model, fit_transformers=False)\n",
    "\n",
    "# Prepare Data\n",
    "TARGETS = [f'BlendProperty{i}' for i in range(1, 11)]\n",
    "X_train = train[feat_cols]\n",
    "y_train = train[TARGETS]\n",
    "X_test = test[feat_cols]\n",
    "\n",
    "# Handle NaN values\n",
    "print(\"Handling NaN values...\")\n",
    "\n",
    "# Handle NaN values\n",
    "print(\"Handling NaN values...\")\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Feature scaling for different models\n",
    "scaler_robust = RobustScaler()\n",
    "X_train_robust = scaler_robust.fit_transform(X_train)\n",
    "X_test_robust = scaler_robust.transform(X_test)\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "X_train_standard = scaler_standard.fit_transform(X_train)\n",
    "X_test_standard = scaler_standard.transform(X_test)\n",
    "\n",
    "# Feature selection for some models\n",
    "print(\"Performing feature selection...\")\n",
    "selector = SelectFromModel(\n",
    "    RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    prefit=False,\n",
    "    threshold='median'\n",
    ")\n",
    "\n",
    "X_train_selected = selector.fit_transform(X_train, y_train.iloc[:, 0])\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "selected_features = [feat_cols[i] for i in range(len(feat_cols)) if selector.get_support()[i]]\n",
    "print(f\"Original features: {len(feat_cols)}\")\n",
    "print(f\"Selected features: {len(selected_features)}\")\n",
    "\n",
    "# Cross-Validation Setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "final_preds = np.zeros((X_test.shape[0], len(TARGETS)))\n",
    "\n",
    "print(\"Training Breakthrough Ensemble...\")\n",
    "print(f\"Features: {len(feat_cols)} (selected: {len(selected_features)})\")\n",
    "\n",
    "for i, target in enumerate(TARGETS):\n",
    "    print(f\"\\nTraining for {target}...\")\n",
    "\n",
    "    # Out-of-fold predictions for each model\n",
    "    rf_oof = np.zeros(X_train.shape[0])\n",
    "    et_oof = np.zeros(X_train.shape[0])\n",
    "    gb_oof = np.zeros(X_train.shape[0])\n",
    "    ridge_oof = np.zeros(X_train.shape[0])\n",
    "    elastic_oof = np.zeros(X_train.shape[0])\n",
    "    huber_oof = np.zeros(X_train.shape[0])\n",
    "    gp_oof = np.zeros(X_train.shape[0])\n",
    "\n",
    "    # Test predictions for each model\n",
    "    rf_test_preds = np.zeros(X_test.shape[0])\n",
    "    et_test_preds = np.zeros(X_test.shape[0])\n",
    "    gb_test_preds = np.zeros(X_test.shape[0])\n",
    "    ridge_test_preds = np.zeros(X_test.shape[0])\n",
    "    elastic_test_preds = np.zeros(X_test.shape[0])\n",
    "    huber_test_preds = np.zeros(X_test.shape[0])\n",
    "    gp_test_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "\n",
    "        # Model 1: Optimized Random Forest\n",
    "        model_rf = RandomForestRegressor(\n",
    "            n_estimators=800, max_depth=20, min_samples_split=5,\n",
    "            min_samples_leaf=2, random_state=fold, n_jobs=-1\n",
    "        )\n",
    "        model_rf.fit(X_train.iloc[tr_idx], y_train[target].iloc[tr_idx])\n",
    "        rf_oof[val_idx] = model_rf.predict(X_train.iloc[val_idx])\n",
    "        rf_test_preds += model_rf.predict(X_test) / kf.get_n_splits()\n",
    "\n",
    "        # Model 2: Extra Trees\n",
    "        model_et = ExtraTreesRegressor(\n",
    "            n_estimators=600, max_depth=18, min_samples_split=3,\n",
    "            min_samples_leaf=1, random_state=fold, n_jobs=-1\n",
    "        )\n",
    "        model_et.fit(X_train.iloc[tr_idx], y_train[target].iloc[tr_idx])\n",
    "        et_oof[val_idx] = model_et.predict(X_train.iloc[val_idx])\n",
    "        et_test_preds += model_et.predict(X_test) / kf.get_n_splits()\n",
    "\n",
    "        # Model 3: Gradient Boosting\n",
    "        model_gb = GradientBoostingRegressor(\n",
    "            n_estimators=200, learning_rate=0.01, max_depth=8,\n",
    "            min_samples_split=5, min_samples_leaf=2, random_state=fold\n",
    "        )\n",
    "\n",
    "        model_gb.fit(X_train.iloc[tr_idx], y_train[target].iloc[tr_idx])\n",
    "        gb_oof[val_idx] = model_gb.predict(X_train.iloc[val_idx])\n",
    "        gb_test_preds += model_gb.predict(X_test) / kf.get_n_splits()\n",
    "\n",
    "        # Model 4: Ridge (with robust scaling)\n",
    "        model_ridge = Ridge(alpha=1.0, random_state=fold)\n",
    "        model_ridge.fit(X_train_robust[tr_idx], y_train[target].iloc[tr_idx])\n",
    "        ridge_oof[val_idx] = model_ridge.predict(X_train_robust[val_idx])\n",
    "        ridge_test_preds += model_ridge.predict(X_test_robust) / kf.get_n_splits()\n",
    "\n",
    "        # Model 5: Elastic Net (with standard scaling)\n",
    "        model_elastic = ElasticNet(alpha=0.5, l1_ratio=0.3, random_state=fold, max_iter=2000)\n",
    "        model_elastic.fit(X_train_standard[tr_idx], y_train[target].iloc[tr_idx])\n",
    "        elastic_oof[val_idx] = model_elastic.predict(X_train_standard[val_idx])\n",
    "        elastic_test_preds += model_elastic.predict(X_test_standard) / kf.get_n_splits()\n",
    "\n",
    "        # Model 6: Huber (robust to outliers)\n",
    "        model_huber = HuberRegressor(alpha=0.01, epsilon=1.35)\n",
    "        model_huber.fit(X_train_robust[tr_idx], y_train[target].iloc[tr_idx])\n",
    "        huber_oof[val_idx] = model_huber.predict(X_train_robust[val_idx])\n",
    "        huber_test_preds += model_huber.predict(X_test_robust) / kf.get_n_splits()\n",
    "        \n",
    "        # Model 7: Enhanced Gaussian Process Regressor (with feature selection for efficiency)\n",
    "        # Use selected features to reduce computational complexity\n",
    "        model_gp = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            GaussianProcessRegressor(\n",
    "                kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0) + WhiteKernel(noise_level=1e-3),\n",
    "                n_restarts_optimizer=10,\n",
    "                random_state=42,\n",
    "                alpha=1e-6\n",
    "            )\n",
    "        )\n",
    "        model_gp.fit(X_train_selected[tr_idx], y_train[target].iloc[tr_idx])\n",
    "        gp_oof[val_idx] = model_gp.predict(X_train_selected[val_idx])\n",
    "        gp_test_preds += model_gp.predict(X_test_selected) / kf.get_n_splits()\n",
    "        \n",
    "\n",
    "    # Calculate individual model MAPE\n",
    "    rf_mape = mean_absolute_percentage_error(y_train[target], rf_oof)\n",
    "    et_mape = mean_absolute_percentage_error(y_train[target], et_oof)\n",
    "    gb_mape = mean_absolute_percentage_error(y_train[target], gb_oof)\n",
    "    ridge_mape = mean_absolute_percentage_error(y_train[target], ridge_oof)\n",
    "    elastic_mape = mean_absolute_percentage_error(y_train[target], elastic_oof)\n",
    "    huber_mape = mean_absolute_percentage_error(y_train[target], huber_oof)\n",
    "    gp_mape = mean_absolute_percentage_error(y_train[target], gp_oof)\n",
    "\n",
    "\n",
    "    #-----\n",
    "    # Advanced ensemble: Exponential weighting based on validation performance\n",
    "    mape_scores = [rf_mape, et_mape, gb_mape, ridge_mape, elastic_mape, huber_mape, gp_mape]\n",
    "    weights = [np.exp(-score * 10) for score in mape_scores]  # Exponential weighting\n",
    "    total_weight = sum(weights)\n",
    "    weights = [w / total_weight for w in weights]\n",
    "\n",
    "    # Final predictions\n",
    "    final_preds[:, i] = (\n",
    "        weights[0] * rf_test_preds +\n",
    "        weights[1] * et_test_preds +\n",
    "        weights[2] * gb_test_preds +\n",
    "        weights[3] * ridge_test_preds +\n",
    "        weights[4] * elastic_test_preds +\n",
    "        weights[5] * huber_test_preds +\n",
    "        weights[6] * gp_test_preds\n",
    "    )\n",
    "\n",
    "    # Ensemble validation score\n",
    "    ensemble_oof = (\n",
    "        weights[0] * rf_oof +\n",
    "        weights[1] * et_oof +\n",
    "        weights[2] * gb_oof +\n",
    "        weights[3] * ridge_oof +\n",
    "        weights[4] * elastic_oof +\n",
    "        weights[5] * huber_oof +\n",
    "        weights[6] * gp_oof\n",
    "    )\n",
    "\n",
    "    ensemble_mape = mean_absolute_percentage_error(y_train[target], ensemble_oof)\n",
    "\n",
    "    print(f\"Random Forest MAPE: {rf_mape:.4f} (weight: {weights[0]:.3f})\")\n",
    "    print(f\"Extra Trees MAPE: {et_mape:.4f} (weight: {weights[1]:.3f})\")\n",
    "    print(f\"Gradient Boosting MAPE: {gb_mape:.4f} (weight: {weights[2]:.3f})\")\n",
    "    print(f\"Ridge MAPE: {ridge_mape:.4f} (weight: {weights[3]:.3f})\")\n",
    "    print(f\"Elastic Net MAPE: {elastic_mape:.4f} (weight: {weights[4]:.3f})\")\n",
    "    print(f\"Huber MAPE: {huber_mape:.4f} (weight: {weights[5]:.3f})\")\n",
    "    print(f\"Gaussian Process MAPE: {gp_mape:.4f} (weight: {weights[6]:.3f})\")\n",
    "    print(f\"Ensemble MAPE: {ensemble_mape:.4f}\")\n",
    "\n",
    "# Additional Stacking Regressor Ensemble\n",
    "print(\"\\nTraining Stacking Regressor...\")\n",
    "stacking_final_preds = np.zeros((X_test.shape[0], len(TARGETS)))\n",
    "\n",
    "for i, target in enumerate(TARGETS):\n",
    "    print(f\"\\nTraining Stacking Regressor for {target}...\")\n",
    "    \n",
    "    # Define base models for stacking\n",
    "    base_models = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=300, max_depth=15, random_state=42, n_jobs=-1)),\n",
    "        ('et', ExtraTreesRegressor(n_estimators=300, max_depth=15, random_state=42, n_jobs=-1)),\n",
    "        ('ridge', Ridge(alpha=1.0, random_state=42)),\n",
    "        ('gp', make_pipeline(\n",
    "            StandardScaler(),\n",
    "            GaussianProcessRegressor(\n",
    "                kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0) + WhiteKernel(noise_level=1e-3),\n",
    "                n_restarts_optimizer=5,\n",
    "                random_state=42,\n",
    "                alpha=1e-6\n",
    "            )\n",
    "        ))\n",
    "    ]\n",
    "    \n",
    "    # Meta-learner\n",
    "    meta_learner = Ridge(alpha=10.0, random_state=42)\n",
    "    \n",
    "    # Create stacking regressor\n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=meta_learner,\n",
    "        cv=3,  # Use 3-fold CV for speed\n",
    "        n_jobs=-1,\n",
    "        passthrough=False\n",
    "    )\n",
    "    \n",
    "    # Train on selected features for efficiency\n",
    "    stacking_regressor.fit(X_train_selected, y_train[target])\n",
    "    stacking_final_preds[:, i] = stacking_regressor.predict(X_test_selected)\n",
    "    \n",
    "    # Calculate stacking validation score\n",
    "    stacking_oof = stacking_regressor.predict(X_train_selected)\n",
    "    stacking_mape = mean_absolute_percentage_error(y_train[target], stacking_oof)\n",
    "    print(f\"Stacking Regressor MAPE for {target}: {stacking_mape:.4f}\")\n",
    "\n",
    "# Combine ensemble and stacking predictions (weighted average)\n",
    "combined_final_preds = 0.7 * final_preds + 0.3 * stacking_final_preds\n",
    "\n",
    "# Create Submission\n",
    "# Create Submission\n",
    "submission = pd.DataFrame(combined_final_preds, columns=TARGETS)\n",
    "submission.insert(0, 'ID', test.get('ID', np.arange(1, len(test) + 1)))\n",
    "submission.to_csv('submission_breakthrough_90plus_with_gp_stacking.csv', index=False)\n",
    "\n",
    "print(\"\\nSubmission file created: submission_breakthrough_90plus_with_gp_stacking.csv\")\n",
    "print(\"\\nBreakthrough Ensemble Summary:\")\n",
    "print(f\"Features: {len(feat_cols)} (selected: {len(selected_features)})\")\n",
    "print(\"Cross-validation: 5-fold\")\n",
    "print(\"Models: Random Forest, Extra Trees, Gradient Boosting, Ridge, Elastic Net, Huber, Gaussian Process\")\n",
    "print(\"Ensemble: Exponential weighting based on validation performance\")\n",
    "print(\"Stacking: Additional Stacking Regressor with Ridge meta-learner\")\n",
    "print(\"Final: Combined ensemble (70%) + stacking (30%) predictions\")\n",
    "print(\"Scaling: Robust and Standard scaling for different models\")\n",
    "print(\"Target: 90+ score with breakthrough features, GP regressor, and advanced stacking ensemble\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fcd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ShellAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
