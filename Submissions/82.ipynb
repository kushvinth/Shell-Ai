{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9760ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from xgboost import XGBRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "# Deployment\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "\n",
    "def GPR_predict(train_df, test_df, property_index):\n",
    "    \"\"\"\n",
    "    Trains a GaussianProcessRegressor model for a single blend property\n",
    "    and makes predictions on the test set.\n",
    "    \"\"\"\n",
    "    features = ['Component1_fraction',\n",
    "                'Component2_fraction',\n",
    "                'Component3_fraction',\n",
    "                'Component4_fraction',\n",
    "                'Component5_fraction',\n",
    "                f'Component1_Property{property_index}',\n",
    "                f'Component2_Property{property_index}',\n",
    "                f'Component3_Property{property_index}',\n",
    "                f'Component4_Property{property_index}',\n",
    "                f'Component5_Property{property_index}']\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[f'BlendProperty{property_index}']\n",
    "\n",
    "    kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0)\n",
    "\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5, random_state=42)\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = test_df[features]\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    return test_predictions\n",
    "\n",
    "def NN_predict(train_df, test_df, property_index):\n",
    "    \"\"\"\n",
    "    Trains a Neural Network model for a single blend property\n",
    "    and makes predictions on the test set.\n",
    "    \"\"\"\n",
    "    features = ['Component1_fraction',\n",
    "                'Component2_fraction',\n",
    "                'Component3_fraction',\n",
    "                'Component4_fraction',\n",
    "                'Component5_fraction',\n",
    "                f'Component1_Property{property_index}',\n",
    "                f'Component2_Property{property_index}',\n",
    "                f'Component3_Property{property_index}',\n",
    "                f'Component4_Property{property_index}',\n",
    "                f'Component5_Property{property_index}']\n",
    "\n",
    "    X_train = train_df[features].values\n",
    "    y_train = train_df[f'BlendProperty{property_index}'].values\n",
    "\n",
    "    # Build model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    X_test = test_df[features].values\n",
    "    test_predictions = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "    return test_predictions\n",
    "\n",
    "\n",
    "def ElasticNet_predict(train_df, test_df, property_index):\n",
    "    \"\"\"\n",
    "    Trains an ElasticNet model for a single blend property\n",
    "    and makes predictions on the test set.\n",
    "    \"\"\"\n",
    "    features = ['Component1_fraction',\n",
    "                'Component2_fraction',\n",
    "                'Component3_fraction',\n",
    "                'Component4_fraction',\n",
    "                'Component5_fraction',\n",
    "                f'Component1_Property{property_index}',\n",
    "                f'Component2_Property{property_index}',\n",
    "                f'Component3_Property{property_index}',\n",
    "                f'Component4_Property{property_index}',\n",
    "                f'Component5_Property{property_index}']\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[f'BlendProperty{property_index}']\n",
    "\n",
    "    model = ElasticNet(\n",
    "        alpha=1.0,       # Regularization strength\n",
    "        l1_ratio=0.5,    # Mix between L1 (lasso) and L2 (ridge)\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = test_df[features]\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    return test_predictions\n",
    "\n",
    "def SVR_RBF_predict(train_df, test_df, property_index):\n",
    "    \"\"\"\n",
    "    Trains an SVR with RBF kernel model for a single blend property\n",
    "    and makes predictions on the test set.\n",
    "    \"\"\"\n",
    "    features = ['Component1_fraction',\n",
    "                'Component2_fraction',\n",
    "                'Component3_fraction',\n",
    "                'Component4_fraction',\n",
    "                'Component5_fraction',\n",
    "                f'Component1_Property{property_index}',\n",
    "                f'Component2_Property{property_index}',\n",
    "                f'Component3_Property{property_index}',\n",
    "                f'Component4_Property{property_index}',\n",
    "                f'Component5_Property{property_index}']\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[f'BlendProperty{property_index}']\n",
    "\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = test_df[features]\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    return test_predictions\n",
    "\n",
    "\n",
    "def RandomForest_predict(train_df, test_df, property_index):\n",
    "    \"\"\"\n",
    "    Trains a RandomForestRegressor model for a single blend property\n",
    "    and makes predictions on the test set.\n",
    "    \"\"\"\n",
    "    features = ['Component1_fraction',\n",
    "                'Component2_fraction',\n",
    "                'Component3_fraction',\n",
    "                'Component4_fraction',\n",
    "                'Component5_fraction',\n",
    "                f'Component1_Property{property_index}',\n",
    "                f'Component2_Property{property_index}',\n",
    "                f'Component3_Property{property_index}',\n",
    "                f'Component4_Property{property_index}',\n",
    "                f'Component5_Property{property_index}']\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[f'BlendProperty{property_index}']\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = test_df[features]\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    return test_predictions\n",
    "\n",
    "def TabNet_predict(train_df, test_df, property_index):\n",
    "    \"\"\"TabNet Regressor to predict a single blend property.\"\"\"\n",
    "\n",
    "\n",
    "    features = ['Component1_fraction',\n",
    "                'Component2_fraction',\n",
    "                'Component3_fraction',\n",
    "                'Component4_fraction',\n",
    "                'Component5_fraction',\n",
    "                f'Component1_Property{property_index}',\n",
    "                f'Component2_Property{property_index}',\n",
    "                f'Component3_Property{property_index}',\n",
    "                f'Component4_Property{property_index}',\n",
    "                f'Component5_Property{property_index}']\n",
    "\n",
    "    X_train = train_df[features].values\n",
    "    y_train = train_df[f'BlendProperty{property_index}'].values.reshape(-1, 1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    model = TabNetRegressor(\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=2e-2),\n",
    "        verbose=0,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train=X_train_scaled, y_train=y_train,\n",
    "        max_epochs=200,\n",
    "        patience=20,\n",
    "        batch_size=256,\n",
    "        virtual_batch_size=128\n",
    "    )\n",
    "\n",
    "    X_test = test_df[features].values\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    test_predictions = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "    return test_predictions\n",
    "\n",
    "\n",
    "def SVR_Poly_predict(train_df, test_df, property_index):\n",
    "    \"\"\"\n",
    "    Trains an SVR with Poly kernel model for a single blend property\n",
    "    and makes predictions on the test set.\n",
    "    \"\"\"\n",
    "    features = ['Component1_fraction',\n",
    "                'Component2_fraction',\n",
    "                'Component3_fraction',\n",
    "                'Component4_fraction',\n",
    "                'Component5_fraction',\n",
    "                f'Component1_Property{property_index}',\n",
    "                f'Component2_Property{property_index}',\n",
    "                f'Component3_Property{property_index}',\n",
    "                f'Component4_Property{property_index}',\n",
    "                f'Component5_Property{property_index}']\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[f'BlendProperty{property_index}']\n",
    "\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVR(kernel='poly', C=1.0, epsilon=0.1)\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = test_df[features]\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    return test_predictions\n",
    "\n",
    "def Lasso_predict(train_df, test_df, property_index):\n",
    "    \"\"\"\n",
    "    Trains a Lasso model for a single blend property\n",
    "    and makes predictions on the test set.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import Lasso\n",
    "\n",
    "    features = ['Component1_fraction',\n",
    "                'Component2_fraction',\n",
    "                'Component3_fraction',\n",
    "                'Component4_fraction',\n",
    "                'Component5_fraction',\n",
    "                f'Component1_Property{property_index}',\n",
    "                f'Component2_Property{property_index}',\n",
    "                f'Component3_Property{property_index}',\n",
    "                f'Component4_Property{property_index}',\n",
    "                f'Component5_Property{property_index}']\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[f'BlendProperty{property_index}']\n",
    "\n",
    "    model = Lasso(alpha=1.0, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = test_df[features]\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    return test_predictions\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"/content/train.csv\")\n",
    "test_df = pd.read_csv(\"/content/test.csv\")\n",
    "submission_df = pd.read_csv(\"/content/sample_solution.csv\")\n",
    "\n",
    "# Define the models to use for each property\n",
    "models = {\n",
    "    1: GPR_predict,\n",
    "    2: NN_predict,\n",
    "    3: ElasticNet_predict,\n",
    "    4: SVR_RBF_predict,\n",
    "    5: RandomForest_predict,\n",
    "    6: TabNet_predict,\n",
    "    7: SVR_Poly_predict,\n",
    "    8: ElasticNet_predict, # ElasticNet used twice\n",
    "    9: Lasso_predict,       # Lasso used\n",
    "    10: NN_predict          # NN used twice\n",
    "}\n",
    "\n",
    "# Generate predictions for each property using the specified model\n",
    "for i in range(1, 11):\n",
    "    model_func = models[i]\n",
    "    print(f\"Generating predictions for BlendProperty{i} using {model_func.__name__}...\")\n",
    "    test_predictions = model_func(train_df, test_df, i)\n",
    "    submission_df[f'BlendProperty{i}'] = test_predictions\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
