{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71464402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing BlendProperty1 for final submission...\n",
      "Training Gaussian_Process for BlendProperty1 on full dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     73\u001b[39m features = [\u001b[33m'\u001b[39m\u001b[33mComponent1_fraction\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mComponent2_fraction\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mComponent3_fraction\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     74\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mComponent4_fraction\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mComponent5_fraction\u001b[39m\u001b[33m'\u001b[39m] + \\\n\u001b[32m     75\u001b[39m           [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mComponent\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_Property\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m6\u001b[39m)]\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Train the best model for this property on the full training data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m trained_model = \u001b[43mget_trained_final_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[32m     81\u001b[39m test_predictions = trained_model.predict(test_df_features[features])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mget_trained_final_model\u001b[39m\u001b[34m(data, target, property_name)\u001b[39m\n\u001b[32m     46\u001b[39m      model = TabNetPipeline(scaler, model) \u001b[38;5;66;03m# Return the wrapped model\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Pipeline): \u001b[38;5;66;03m# Check against the Pipeline class\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Pipeline handles scaling internally\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     50\u001b[39m     model.fit(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:661\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    656\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    657\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    658\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    659\u001b[39m             all_params=params,\n\u001b[32m    660\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:311\u001b[39m, in \u001b[36mGaussianProcessRegressor.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[38;5;28mself\u001b[39m.log_marginal_likelihood(theta, clone_kernel=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# First optimize starting from theta specified in kernel\u001b[39;00m\n\u001b[32m    309\u001b[39m optima = [\n\u001b[32m    310\u001b[39m     (\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbounds\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m     )\n\u001b[32m    315\u001b[39m ]\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# Additional runs are performed from log-uniform chosen initial\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_restarts_optimizer > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:656\u001b[39m, in \u001b[36mGaussianProcessRegressor._constrained_optimization\u001b[39m\u001b[34m(self, obj_func, initial_theta, bounds)\u001b[39m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.optimizer == \u001b[33m\"\u001b[39m\u001b[33mfmin_l_bfgs_b\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         opt_res = \u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m         _check_optimize_result(\u001b[33m\"\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m\"\u001b[39m, opt_res)\n\u001b[32m    664\u001b[39m         theta_opt, func_min = opt_res.x, opt_res.fun\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/scipy/optimize/_minimize.py:785\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    782\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    783\u001b[39m                              **options)\n\u001b[32m    784\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    788\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    789\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:469\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    461\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    472\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:403\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(x, \u001b[38;5;28mself\u001b[39m.x):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad()\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:353\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m         fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m         \u001b[38;5;28mself\u001b[39m._nfev += \u001b[32m1\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fx < \u001b[38;5;28mself\u001b[39m._lowest_f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/scipy/_lib/_util.py:583\u001b[39m, in \u001b[36m_ScalarFunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    581\u001b[39m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    582\u001b[39m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    586\u001b[39m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:80\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:74\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:301\u001b[39m, in \u001b[36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[39m\u001b[34m(theta, eval_gradient)\u001b[39m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobj_func\u001b[39m(theta, eval_gradient=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m         lml, grad = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m -lml, -grad\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:643\u001b[39m, in \u001b[36mGaussianProcessRegressor.log_marginal_likelihood\u001b[39m\u001b[34m(self, theta, eval_gradient, clone_kernel)\u001b[39m\n\u001b[32m    632\u001b[39m inner_term -= K_inv[..., np.newaxis]\n\u001b[32m    633\u001b[39m \u001b[38;5;66;03m# Since we are interested about the trace of\u001b[39;00m\n\u001b[32m    634\u001b[39m \u001b[38;5;66;03m# inner_term @ K_gradient, we don't explicitly compute the\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[38;5;66;03m# matrix-by-matrix operation and instead use an einsum. Therefore\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    641\u001b[39m \u001b[38;5;66;03m#             K_gradient[..., param_idx]\u001b[39;00m\n\u001b[32m    642\u001b[39m \u001b[38;5;66;03m#         )\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m log_likelihood_gradient_dims = \u001b[32m0.5\u001b[39m * \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mijl,jik->kl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_term\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_gradient\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[38;5;66;03m# the log likelihood gradient is the sum-up across the outputs\u001b[39;00m\n\u001b[32m    647\u001b[39m log_likelihood_gradient = log_likelihood_gradient_dims.sum(axis=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/numpy/_core/einsumfunc.py:1429\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(out, optimize, *operands, **kwargs)\u001b[39m\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[32m   1428\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m] = out\n\u001b[32m-> \u001b[39m\u001b[32m1429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[32m   1433\u001b[39m valid_einsum_kwargs = [\u001b[33m'\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcasting\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/train.csv\")\n",
    "# Define a function to get the trained model for each property based on the analysis\n",
    "def get_trained_final_model(data, target, property_name):\n",
    "    \"\"\"\n",
    "    Trains the best performing model for a specific blend property on the full training data.\n",
    "    \"\"\"\n",
    "    # Define the final models and their parameters based on the analysis\n",
    "    final_model_info = {\n",
    "        'BlendProperty1': ('Gaussian_Process', make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0), n_restarts_optimizer=5, random_state=42))),\n",
    "        'BlendProperty2': ('Gaussian_Process', make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0), n_restarts_optimizer=5, random_state=42))),\n",
    "        'BlendProperty3': ('ElasticNet', ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)), \n",
    "        'BlendProperty4': ('Gaussian_Process', make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0), n_restarts_optimizer=5, random_state=42))),\n",
    "        'BlendProperty5': ('Random_Forest', RandomForestRegressor(n_estimators=100, max_depth=11, random_state=42, n_jobs=-1)),\n",
    "        'BlendProperty6': ('Gaussian_Process', make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0), n_restarts_optimizer=5, random_state=42))),\n",
    "        'BlendProperty7': ('SVR_Poly', make_pipeline(StandardScaler(), SVR(kernel='poly', C=1.0, epsilon=0.1))),\n",
    "        'BlendProperty8': ('ElasticNet', ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)),\n",
    "        'BlendProperty9': ('ElasticNet', ElasticNet(alpha=1.0, l1_ratio=0, random_state=42)),\n",
    "        'BlendProperty10': ('Neural_Network', Sequential([Dense(64, activation='relu', input_shape=(data.shape[1],)), Dropout(0.2), Dense(64, activation='relu'), Dense(1)]))\n",
    "    }\n",
    "\n",
    "    model_name, model = final_model_info[property_name]\n",
    "\n",
    "    X = data\n",
    "    y = target\n",
    "\n",
    "    print(f\"Training {model_name} for {property_name} on full dataset...\")\n",
    "\n",
    "    if model_name == 'Neural_Network':\n",
    "        model.compile(optimizer='adam', loss='mae')\n",
    "        model.fit(X, y, epochs=100, batch_size=32, verbose=0)\n",
    "    elif model_name == 'TabNet':\n",
    "         # TabNet requires numpy and potential scaling\n",
    "         X_np = X.values\n",
    "         y_np = y.values.reshape(-1, 1)\n",
    "         scaler = StandardScaler()\n",
    "         X_scaled = scaler.fit_transform(X_np)\n",
    "         model.fit(X_scaled, y_np, max_epochs=200, patience=20, batch_size=256, virtual_batch_size=128, verbose=0)\n",
    "         # Wrap TabNet model and scaler in a pipeline for consistent prediction interface\n",
    "         class TabNetPipeline:\n",
    "             def __init__(self, scaler, tabnet_model):\n",
    "                 self.scaler = scaler\n",
    "                 self.tabnet_model = tabnet_model\n",
    "             def predict(self, X):\n",
    "                 X_scaled = self.scaler.transform(X.values)\n",
    "                 return self.tabnet_model.predict(X_scaled).flatten()\n",
    "         model = TabNetPipeline(scaler, model) # Return the wrapped model\n",
    "    elif isinstance(model, Pipeline): # Check against the Pipeline class\n",
    "        model.fit(X, y) # Pipeline handles scaling internally\n",
    "    else:\n",
    "        model.fit(X, y)\n",
    "\n",
    "    print(f\"Training complete for {property_name}.\")\n",
    "    return model\n",
    "\n",
    "# Load test data and sample submission\n",
    "# Assuming test.csv and sample_solution.csv are in the current directory\n",
    "try:\n",
    "  test_df = pd.read_csv(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/test.csv\")\n",
    "  submission_df = pd.read_csv(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/sample_solution.csv\")\n",
    "  test_ids = test_df['ID']\n",
    "  test_df_features = test_df.drop(columns=['ID'])\n",
    "except FileNotFoundError:\n",
    "    print(\"Make sure 'test.csv' and 'sample_solution.csv' are uploaded to your Colab session.\")\n",
    "\n",
    "\n",
    "if 'test_df_features' in locals(): # Check if test data was loaded\n",
    "  # Generate predictions using the best model for each property\n",
    "  for i in range(1, 11):\n",
    "      property_name = f'BlendProperty{i}'\n",
    "      print(f\"\\nProcessing {property_name} for final submission...\")\n",
    "\n",
    "      # Define features for this property\n",
    "      features = ['Component1_fraction', 'Component2_fraction', 'Component3_fraction',\n",
    "                 'Component4_fraction', 'Component5_fraction'] + \\\n",
    "                [f'Component{j}_Property{i}' for j in range(1, 6)]\n",
    "\n",
    "      # Train the best model for this property on the full training data\n",
    "      trained_model = get_trained_final_model(df[features], df[property_name], property_name)\n",
    "\n",
    "      # Make predictions on the test data\n",
    "      test_predictions = trained_model.predict(test_df_features[features])\n",
    "\n",
    "      # Update the submission DataFrame\n",
    "      submission_df[property_name] = test_predictions\n",
    "\n",
    "  # Save the final submission file\n",
    "  submission_df.to_csv('daddy.csv', index=False)\n",
    "\n",
    "  print(\"\\n\" + \"=\"*80)\n",
    "  print(\"Final submission file 'daddy.csv' created successfully.\")\n",
    "  print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure 'test.csv' and 'sample_solution.csv' are uploaded to your Colab session.\n",
      "\n",
      "Processing BlendProperty1 for final submission...\n",
      "Training Gaussian_Process for BlendProperty1 on full dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge after 11 iteration(s) (status=2):\n",
      "ABNORMAL: \n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge after 8 iteration(s) (status=2):\n",
      "ABNORMAL: \n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for BlendProperty1.\n",
      "\n",
      "Processing BlendProperty2 for final submission...\n",
      "Training Gaussian_Process for BlendProperty2 on full dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for BlendProperty2.\n",
      "\n",
      "Processing BlendProperty3 for final submission...\n",
      "Training ElasticNet for BlendProperty3 on full dataset...\n",
      "Training complete for BlendProperty3.\n",
      "\n",
      "Processing BlendProperty4 for final submission...\n",
      "Training Gaussian_Process for BlendProperty4 on full dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge after 9 iteration(s) (status=2):\n",
      "ABNORMAL: \n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for BlendProperty4.\n",
      "\n",
      "Processing BlendProperty5 for final submission...\n",
      "Training Random_Forest for BlendProperty5 on full dataset...\n",
      "Training complete for BlendProperty5.\n",
      "\n",
      "Processing BlendProperty6 for final submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gaussian_Process for BlendProperty6 on full dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge after 10 iteration(s) (status=2):\n",
      "ABNORMAL: \n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for BlendProperty6.\n",
      "\n",
      "Processing BlendProperty7 for final submission...\n",
      "Training SVR_Poly for BlendProperty7 on full dataset...\n",
      "Training complete for BlendProperty7.\n",
      "\n",
      "Processing BlendProperty8 for final submission...\n",
      "Training ElasticNet for BlendProperty8 on full dataset...\n",
      "Training complete for BlendProperty8.\n",
      "\n",
      "Processing BlendProperty9 for final submission...\n",
      "Training ElasticNet for BlendProperty9 on full dataset...\n",
      "Training complete for BlendProperty9.\n",
      "\n",
      "Processing BlendProperty10 for final submission...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/MacbookPro/LocalStorage/Developer/ShellAi/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural_Network for BlendProperty10 on full dataset...\n",
      "Training complete for BlendProperty10.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      "================================================================================\n",
      "Final submission file 'final_model_submission.csv' created successfully.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline # Import Pipeline\n",
    "\n",
    "# Define a function to get the trained model for each property based on the analysis\n",
    "def get_trained_final_model(data, target, property_name):\n",
    "    \"\"\"\n",
    "    Trains the best performing model for a specific blend property on the full training data.\n",
    "    \"\"\"\n",
    "    # Define the final models and their parameters based on the analysis\n",
    "    final_model_info = {\n",
    "        'BlendProperty1': ('Gaussian_Process', make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0), n_restarts_optimizer=5, random_state=42))),\n",
    "        'BlendProperty2': ('Gaussian_Process', make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0), n_restarts_optimizer=5, random_state=42))),\n",
    "        'BlendProperty3': ('ElasticNet', ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)),\n",
    "        'BlendProperty4': ('Gaussian_Process', make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0), n_restarts_optimizer=5, random_state=42))),\n",
    "        'BlendProperty5': ('Random_Forest', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)),\n",
    "        'BlendProperty6': ('Gaussian_Process', make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=C(1.0, (1e-3, 1e3)) * RBF(length_scale=2.0), n_restarts_optimizer=5, random_state=42))),\n",
    "        'BlendProperty7': ('SVR_Poly', make_pipeline(StandardScaler(), SVR(kernel='poly', C=1.0, epsilon=0.1))),\n",
    "        'BlendProperty8': ('ElasticNet', ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)),\n",
    "        'BlendProperty9': ('ElasticNet', ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)),\n",
    "        'BlendProperty10': ('Neural_Network', Sequential([Dense(64, activation='relu', input_shape=(data.shape[1],)), Dropout(0.2), Dense(64, activation='relu'), Dense(1)]))\n",
    "    }\n",
    "\n",
    "    model_name, model = final_model_info[property_name]\n",
    "\n",
    "    X = data\n",
    "    y = target\n",
    "\n",
    "    print(f\"Training {model_name} for {property_name} on full dataset...\")\n",
    "\n",
    "    if model_name == 'Neural_Network':\n",
    "        model.compile(optimizer='adam', loss='mae')\n",
    "        model.fit(X, y, epochs=100, batch_size=32, verbose=0)\n",
    "    elif model_name == 'TabNet':\n",
    "         # TabNet requires numpy and potential scaling\n",
    "         X_np = X.values\n",
    "         y_np = y.values.reshape(-1, 1)\n",
    "         scaler = StandardScaler()\n",
    "         X_scaled = scaler.fit_transform(X_np)\n",
    "         model.fit(X_scaled, y_np, max_epochs=200, patience=20, batch_size=256, virtual_batch_size=128, verbose=0)\n",
    "         # Wrap TabNet model and scaler in a pipeline for consistent prediction interface\n",
    "         class TabNetPipeline:\n",
    "             def __init__(self, scaler, tabnet_model):\n",
    "                 self.scaler = scaler\n",
    "                 self.tabnet_model = tabnet_model\n",
    "             def predict(self, X):\n",
    "                 X_scaled = self.scaler.transform(X.values)\n",
    "                 return self.tabnet_model.predict(X_scaled).flatten()\n",
    "         model = TabNetPipeline(scaler, model) # Return the wrapped model\n",
    "    elif isinstance(model, Pipeline): # Check against the Pipeline class\n",
    "        model.fit(X, y) # Pipeline handles scaling internally\n",
    "    else:\n",
    "        model.fit(X, y)\n",
    "\n",
    "    print(f\"Training complete for {property_name}.\")\n",
    "    return model\n",
    "\n",
    "# Load test data and sample submission\n",
    "# Assuming test.csv and sample_solution.csv are in the current directory\n",
    "try:\n",
    "  test_df = pd.read_csv(\"test.csv\")\n",
    "  submission_df = pd.read_csv(\"sample_solution.csv\")\n",
    "  test_ids = test_df['ID']\n",
    "  test_df_features = test_df.drop(columns=['ID'])\n",
    "except FileNotFoundError:\n",
    "    print(\"Make sure 'test.csv' and 'sample_solution.csv' are uploaded to your Colab session.\")\n",
    "\n",
    "\n",
    "if 'test_df_features' in locals(): # Check if test data was loaded\n",
    "  # Generate predictions using the best model for each property\n",
    "  for i in range(1, 11):\n",
    "      property_name = f'BlendProperty{i}'\n",
    "      print(f\"\\nProcessing {property_name} for final submission...\")\n",
    "\n",
    "      # Define features for this property\n",
    "      features = ['Component1_fraction', 'Component2_fraction', 'Component3_fraction',\n",
    "                 'Component4_fraction', 'Component5_fraction'] + \\\n",
    "                [f'Component{j}_Property{i}' for j in range(1, 6)]\n",
    "\n",
    "      # Train the best model for this property on the full training data\n",
    "      trained_model = get_trained_final_model(df[features], df[property_name], property_name)\n",
    "\n",
    "      # Make predictions on the test data\n",
    "      test_predictions = trained_model.predict(test_df_features[features])\n",
    "\n",
    "      # Update the submission DataFrame\n",
    "      submission_df[property_name] = test_predictions\n",
    "\n",
    "  # Save the final submission file\n",
    "  submission_df.to_csv('final_model_submission.csv', index=False)\n",
    "\n",
    "  print(\"\\n\" + \"=\"*80)\n",
    "  print(\"Final submission file 'final_model_submission.csv' created successfully.\")\n",
    "  print(\"=\"*80)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d593ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
