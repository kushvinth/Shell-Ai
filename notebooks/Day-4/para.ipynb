{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dda21ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ Training model for BlendProperty1...\n",
      "\n",
      "ðŸ”§ Training model for BlendProperty2...\n",
      "\n",
      "ðŸ”§ Training model for BlendProperty3...\n",
      "\n",
      "ðŸ”§ Training model for BlendProperty4...\n",
      "\n",
      "ðŸ”§ Training model for BlendProperty5...\n",
      "\n",
      "ðŸ”§ Training model for BlendProperty6...\n",
      "\n",
      "ðŸ”§ Training model for BlendProperty7...\n",
      "\n",
      "ðŸ”§ Training model for BlendProperty8...\n",
      "\n",
      "ðŸ”§ Training model for BlendProperty9...\n",
      "\n",
      "ðŸ”§ Training model for BlendProperty10...\n",
      "\n",
      "âœ… Final submission file 'oka.csv' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/test.csv\")\n",
    "submission_df = pd.read_csv(\"/Users/MacbookPro/LocalStorage/Developer/ShellAi/dataset/sample_solution.csv\")\n",
    "\n",
    "# Drop ID\n",
    "test_ids = test_df['ID']\n",
    "test_df_features = test_df.drop(columns=['ID'])\n",
    "\n",
    "# Define top 10 correlated features per BlendProperty based on image\n",
    "top_corr_features = {\n",
    "    'BlendProperty1': ['Component5_fraction', 'Component2_fraction', 'Component3_fraction', 'Component1_fraction', 'Component2_Property1', 'Component3_Property1', 'Component5_Property1', 'Component4_Property1', 'Component1_Property1', 'Component1_Property5'],\n",
    "    'BlendProperty2': ['Component3_fraction', 'Component2_fraction', 'Component4_fraction', 'Component3_Property2', 'Component5_fraction', 'Component2_Property2', 'Component1_fraction', 'Component1_Property2', 'Component4_Property2', 'Component2_Property3'],\n",
    "    'BlendProperty3': ['Component2_fraction', 'Component3_fraction', 'Component3_Property3', 'Component2_Property3', 'Component4_Property3', 'Component5_fraction', 'Component1_fraction', 'Component2_Property2', 'Component3_Property2', 'Component5_Property3'],\n",
    "    'BlendProperty4': ['Component5_fraction', 'Component2_fraction', 'Component1_fraction', 'Component3_fraction', 'Component4_fraction', 'Component1_Property4', 'Component3_Property4', 'Component2_Property4', 'Component5_Property4', 'Component4_Property4'],\n",
    "    'BlendProperty5': ['Component2_fraction', 'Component4_fraction', 'Component3_fraction', 'Component2_Property5', 'Component3_Property5', 'Component5_Property5', 'Component1_fraction', 'Component1_Property5', 'Component5_fraction', 'Component4_Property5'],\n",
    "    'BlendProperty6': ['Component5_fraction', 'Component2_fraction', 'Component3_fraction', 'Component1_fraction', 'Component4_fraction', 'Component2_Property6', 'Component5_Property6', 'Component1_Property6', 'Component4_Property6', 'Component3_Property6'],\n",
    "    'BlendProperty7': ['Component2_fraction', 'Component3_fraction', 'Component5_fraction', 'Component1_fraction', 'Component4_fraction', 'Component2_Property7', 'Component3_Property7', 'Component4_Property7', 'Component5_Property7', 'Component1_Property7'],\n",
    "    'BlendProperty8': ['Component2_fraction', 'Component3_fraction', 'Component4_fraction', 'Component1_fraction', 'Component5_fraction', 'Component1_Property8', 'Component3_Property8', 'Component4_Property8', 'Component2_Property8', 'Component5_Property8'],\n",
    "    'BlendProperty9': ['Component4_fraction', 'Component5_fraction', 'Component2_fraction', 'Component3_fraction', 'Component1_fraction', 'Component5_Property9', 'Component3_Property9', 'Component4_Property9', 'Component1_Property9', 'Component2_Property9'],\n",
    "    'BlendProperty10': ['Component4_fraction', 'Component2_fraction', 'Component5_fraction', 'Component3_fraction', 'Component1_fraction', 'Component1_Property10', 'Component2_Property10', 'Component3_Property10', 'Component5_Property10', 'Component4_Property10'],\n",
    "}\n",
    "\n",
    "# Define the best model per BlendProperty (based on image correlation)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def get_best_model_for_property(X, y, prop_name):\n",
    "    if prop_name in ['BlendProperty1', 'BlendProperty2', 'BlendProperty3', 'BlendProperty10']:\n",
    "        return ElasticNet(alpha=0.1, l1_ratio=0.7, random_state=42).fit(X, y)\n",
    "    elif prop_name in ['BlendProperty4', 'BlendProperty8']:\n",
    "        return RandomForestRegressor(n_estimators=200, max_depth=12, random_state=42, n_jobs=-1).fit(X, y)\n",
    "    elif prop_name in ['BlendProperty5', 'BlendProperty9']:\n",
    "        return make_pipeline(StandardScaler(), SVR(kernel='rbf', C=2.0, epsilon=0.1)).fit(X, y)\n",
    "    elif prop_name == 'BlendProperty6':\n",
    "        return make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=C(1.0) * RBF(length_scale=1.0), n_restarts_optimizer=7, random_state=42)).fit(X, y)\n",
    "    elif prop_name == 'BlendProperty7':\n",
    "        return Lasso(alpha=0.05, random_state=42).fit(X, y)\n",
    "    else:  # Neural Network for Property10\n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
    "            Dropout(0.3),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mae')\n",
    "        model.fit(X, y, epochs=200, batch_size=64, verbose=0)\n",
    "        return model\n",
    "\n",
    "# Train, Predict, and Submit\n",
    "for i in range(1, 11):\n",
    "    prop = f'BlendProperty{i}'\n",
    "    print(f\"\\nðŸ”§ Training model for {prop}...\")\n",
    "\n",
    "    features = top_corr_features[prop]  # No weighted properties now\n",
    "    X_train = df[features]\n",
    "    y_train = df[prop]\n",
    "    X_test = test_df_features[features]\n",
    "\n",
    "    model = get_best_model_for_property(X_train, y_train, prop)\n",
    "\n",
    "    # Predict\n",
    "    if isinstance(model, Sequential):\n",
    "        preds = model.predict(X_test).flatten()\n",
    "    else:\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "    submission_df[prop] = preds\n",
    "\n",
    "# Save final CSV\n",
    "submission_df['ID'] = test_ids\n",
    "submission_df.to_csv('oka.csv', index=False)\n",
    "print(\"\\nâœ… Final submission file 'oka.csv' created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65d4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ShellAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
